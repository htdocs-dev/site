{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"For full documentation visit mkdocs.org . Todo 12 months, 12 micro-projects mailer test to json clone reacher templator / generate pdf html renderer / record test site content as a service opsy / pipeline spinner online cron / ping scheduler docker run workflow / simple UI/json / DAG TODOs \u00b6 Setup website First contents Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout \u00b6 1 2 3 4 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to HTDocs"},{"location":"#todos","text":"Setup website First contents","title":"TODOs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"1 2 3 4 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"contact/","text":"Contact \u00b6","title":"Contact"},{"location":"contact/#contact","text":"","title":"Contact"},{"location":"cookbooks/airflow/","text":"","title":"Index"},{"location":"cookbooks/argo/","text":"","title":"Index"},{"location":"cookbooks/docker_swarm/","text":"","title":"Index"},{"location":"cookbooks/kubernetes/","text":"Kubernetes \u00b6 Concepts \u00b6 Kubernetes Concepts Before diving in, let\u2019s look at some of the basic building blocks that you have to work with from the Kubernetes API: A Node is a worker machine provisioned to run Kubernetes. Each Node is managed by the Kubernetes master. A Pod is a logical, tightly-coupled group of application containers that run on a Node. Containers in a Pod are deployed together and share resources (like data volumes and network addresses). Multiple Pods can run on a single Node. A Service is a logical set of Pods that perform a similar function. It enables load balancing and service discovery. It\u2019s an abstraction layer over the Pods; Pods are meant to be ephemeral while services are much more persistent. Deployments are used to describe the desired state of Kubernetes. They dictate how Pods are created, deployed, and replicated. Labels are key/value pairs that are attached to resources (like Pods) which are used to organize related resources. You can think of them like CSS selectors. For example: Environment - dev, test, prod App version - beta, 1.2.1 Type - client, server, db Ingress is a set of routing rules used to control the external access to Services based on the request host or path. Volumes are used to persist data beyond the life of a container. They are especially important for stateful applications like Redis and Postgres. A PersistentVolume defines a storage volume independent of the normal Pod-lifecycle. It\u2019s managed outside of the particular Pod that it resides in. A PersistentVolumeClaim is a request to use the PersistentVolume by a user.","title":"Index"},{"location":"cookbooks/kubernetes/#kubernetes","text":"","title":"Kubernetes"},{"location":"cookbooks/kubernetes/#concepts","text":"Kubernetes Concepts Before diving in, let\u2019s look at some of the basic building blocks that you have to work with from the Kubernetes API: A Node is a worker machine provisioned to run Kubernetes. Each Node is managed by the Kubernetes master. A Pod is a logical, tightly-coupled group of application containers that run on a Node. Containers in a Pod are deployed together and share resources (like data volumes and network addresses). Multiple Pods can run on a single Node. A Service is a logical set of Pods that perform a similar function. It enables load balancing and service discovery. It\u2019s an abstraction layer over the Pods; Pods are meant to be ephemeral while services are much more persistent. Deployments are used to describe the desired state of Kubernetes. They dictate how Pods are created, deployed, and replicated. Labels are key/value pairs that are attached to resources (like Pods) which are used to organize related resources. You can think of them like CSS selectors. For example: Environment - dev, test, prod App version - beta, 1.2.1 Type - client, server, db Ingress is a set of routing rules used to control the external access to Services based on the request host or path. Volumes are used to persist data beyond the life of a container. They are especially important for stateful applications like Redis and Postgres. A PersistentVolume defines a storage volume independent of the normal Pod-lifecycle. It\u2019s managed outside of the particular Pod that it resides in. A PersistentVolumeClaim is a request to use the PersistentVolume by a user.","title":"Concepts"},{"location":"cookbooks/portainer/","text":"","title":"Index"},{"location":"cookbooks/portainer/wordpress/","text":"EasyEngine did switch from installing php stack directly to the system to use docker images to create the different environments, but using command line. Using Portainer, we can skip those steps and manage deployment directly from the interface and control everything. But first we need to setup the system: System installation \u00b6 Create a VPS with Ubuntu 20.04 LTS Install webmin/virtualmin \u00b6 (optional) 1 2 wget http://software.virtualmin.com/gpl/scripts/install.sh sudo /bin/sh install.sh Install Portainer \u00b6 (required) 1 2 3 4 5 apt update apt upgrade apt install docker.io docker volume create portainer_data docker run -d -p 8000 :8000 -p 9000 :9000 --name = portainer --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce Setup layers \u00b6 Network \u00b6 We need 2 network, one to deal with outside world, managed by traefik, and another one for backend communication with the dabatabse, not accessible from outside will be created by each stack. 1 docker create network -d bridge traefik Each stack will create their own network. Or directly in the UI: Then we need to install 2 pieces of infra: the router / load blancer, Treafik, and the datbase mariadb. traefik \u00b6 At the moment portainer only accept docker compose v2 definition 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 version : \"2\" services : traefik : image : \"traefik:v2.3\" container_name : \"traefik\" command : - \"--api.insecure=true\" - \"--providers.docker=true\" - \"--providers.docker.exposedbydefault=false\" - \"--entrypoints.web.address=:80\" - \"--entrypoints.web-secure.address=:443\" - \"--certificatesresolvers.myhttpchallenge.acme.httpchallenge=true\" - \"--certificatesresolvers.myhttpchallenge.acme.httpchallenge.entrypoint=web\" - \"--pilot.token=df5c63a6-9fc1-4253-9c36-62f0ed4548c1\" - \"--certificatesresolvers.myhttpchallenge.acme.email=stephane.busso@gmail.com\" - \"--certificatesresolvers.myhttpchallenge.acme.storage=/letsencrypt/acme.json\" ports : - \"80:80\" - \"443:443\" - \"8080:8080\" volumes : - \"/var/run/docker.sock:/var/run/docker.sock:ro\" - \"/etc/letsencrypt:/letsencrypt\" networks : - traefik networks : traefik : external : name : traefik Wordpress stack \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 version : \"2\" services : db : image : mariadb:latest volumes : - /var/lib/mysql:/var/lib/mysql:/var/lib/mysql restart : always environment : MYSQL_ROOT_PASSWORD : PASSWORD MYSQL_DATABASE : WP MYSQL_USER : WPUSER MYSQL_PASSWORD : WPPASSWD networks : - backend wordpress : depends_on : - db image : wordpress # wordpress with apache restart : always environment : WORDPRESS_DB_HOST : db:3306 WORDPRESS_DB_USER : WPUSER WORDPRESS_DB_PASSWORD : WPPASSWD networks : - traefik - backend labels : # The labels are usefull for Traefik only - \"traefik.enable=true\" - \"traefik.docker.network=traefik_default\" # Get the routes from http - \"traefik.http.routers.${SERVICE}.rule=Host(`${DOMAIN}`)\" - \"traefik.http.routers.${SERVICE}.entrypoints=web\" # Redirect these routes to https - \"traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https\" - \"traefik.http.routers.${SERVICE}.middlewares=redirect-to-https@docker\" # Get the routes from https - \"traefik.http.routers.${SERVICE}-secured.rule=Host(`${DOMAIN}`)\" - \"traefik.http.routers.${SERVICE}-secured.entrypoints=web-secure\" # Apply autentificiation with http challenge - \"traefik.http.routers.${SERVICE}-secured.tls=true\" - \"traefik.http.routers.${SERVICE}-secured.tls.certresolver=myhttpchallenge\" volumes : db_data : networks : traefik : external : name : traefik backend : Voil\u00e0 , after few minutes (time for traefik to get certificates) you should be able to access wordpress at the address in DOMAIN Conclusion \u00b6 What I have learned, it is not always good to optimise things,different paradigm, containers have to keep simple and indempotent, 1 database per stack instead of 1 central and fpm vs apache/php was too complex to operate.","title":"Easy Wordpress hosting with Docker and Portainer"},{"location":"cookbooks/portainer/wordpress/#system-installation","text":"Create a VPS with Ubuntu 20.04 LTS","title":"System installation"},{"location":"cookbooks/portainer/wordpress/#install-webminvirtualmin","text":"(optional) 1 2 wget http://software.virtualmin.com/gpl/scripts/install.sh sudo /bin/sh install.sh","title":"Install webmin/virtualmin"},{"location":"cookbooks/portainer/wordpress/#install-portainer","text":"(required) 1 2 3 4 5 apt update apt upgrade apt install docker.io docker volume create portainer_data docker run -d -p 8000 :8000 -p 9000 :9000 --name = portainer --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce","title":"Install Portainer"},{"location":"cookbooks/portainer/wordpress/#setup-layers","text":"","title":"Setup layers"},{"location":"cookbooks/portainer/wordpress/#network","text":"We need 2 network, one to deal with outside world, managed by traefik, and another one for backend communication with the dabatabse, not accessible from outside will be created by each stack. 1 docker create network -d bridge traefik Each stack will create their own network. Or directly in the UI: Then we need to install 2 pieces of infra: the router / load blancer, Treafik, and the datbase mariadb.","title":"Network"},{"location":"cookbooks/portainer/wordpress/#traefik","text":"At the moment portainer only accept docker compose v2 definition 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 version : \"2\" services : traefik : image : \"traefik:v2.3\" container_name : \"traefik\" command : - \"--api.insecure=true\" - \"--providers.docker=true\" - \"--providers.docker.exposedbydefault=false\" - \"--entrypoints.web.address=:80\" - \"--entrypoints.web-secure.address=:443\" - \"--certificatesresolvers.myhttpchallenge.acme.httpchallenge=true\" - \"--certificatesresolvers.myhttpchallenge.acme.httpchallenge.entrypoint=web\" - \"--pilot.token=df5c63a6-9fc1-4253-9c36-62f0ed4548c1\" - \"--certificatesresolvers.myhttpchallenge.acme.email=stephane.busso@gmail.com\" - \"--certificatesresolvers.myhttpchallenge.acme.storage=/letsencrypt/acme.json\" ports : - \"80:80\" - \"443:443\" - \"8080:8080\" volumes : - \"/var/run/docker.sock:/var/run/docker.sock:ro\" - \"/etc/letsencrypt:/letsencrypt\" networks : - traefik networks : traefik : external : name : traefik","title":"traefik"},{"location":"cookbooks/portainer/wordpress/#wordpress-stack","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 version : \"2\" services : db : image : mariadb:latest volumes : - /var/lib/mysql:/var/lib/mysql:/var/lib/mysql restart : always environment : MYSQL_ROOT_PASSWORD : PASSWORD MYSQL_DATABASE : WP MYSQL_USER : WPUSER MYSQL_PASSWORD : WPPASSWD networks : - backend wordpress : depends_on : - db image : wordpress # wordpress with apache restart : always environment : WORDPRESS_DB_HOST : db:3306 WORDPRESS_DB_USER : WPUSER WORDPRESS_DB_PASSWORD : WPPASSWD networks : - traefik - backend labels : # The labels are usefull for Traefik only - \"traefik.enable=true\" - \"traefik.docker.network=traefik_default\" # Get the routes from http - \"traefik.http.routers.${SERVICE}.rule=Host(`${DOMAIN}`)\" - \"traefik.http.routers.${SERVICE}.entrypoints=web\" # Redirect these routes to https - \"traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https\" - \"traefik.http.routers.${SERVICE}.middlewares=redirect-to-https@docker\" # Get the routes from https - \"traefik.http.routers.${SERVICE}-secured.rule=Host(`${DOMAIN}`)\" - \"traefik.http.routers.${SERVICE}-secured.entrypoints=web-secure\" # Apply autentificiation with http challenge - \"traefik.http.routers.${SERVICE}-secured.tls=true\" - \"traefik.http.routers.${SERVICE}-secured.tls.certresolver=myhttpchallenge\" volumes : db_data : networks : traefik : external : name : traefik backend : Voil\u00e0 , after few minutes (time for traefik to get certificates) you should be able to access wordpress at the address in DOMAIN","title":"Wordpress stack"},{"location":"cookbooks/portainer/wordpress/#conclusion","text":"What I have learned, it is not always good to optimise things,different paradigm, containers have to keep simple and indempotent, 1 database per stack instead of 1 central and fpm vs apache/php was too complex to operate.","title":"Conclusion"},{"location":"cookbooks/postfix/","text":"This is a compiled documentation to administrate a Postfix server for outgoing email Disclaimer This setup documentation was realised on Ubuntu 12.04 and would need update for more recent ubuntu and Postfix This documentation is a compilation of information gathered over the years to build an outgoing mail server with postfix. This is not aiming to be a all go configuration and open sourced for contribution. Main Sections \u00b6 A concise guide. If you just want a robust outgoing mail server, you don\u2019t need to spend $4500 in a PowerMTA solution. Here we show you how to setup your own SMTP, spam filter proof able to send 300 000 email an hour. Ubuntu 12.04.4 LTS","title":"Postfix handbook Site"},{"location":"cookbooks/postfix/#main-sections","text":"A concise guide. If you just want a robust outgoing mail server, you don\u2019t need to spend $4500 in a PowerMTA solution. Here we show you how to setup your own SMTP, spam filter proof able to send 300 000 email an hour. Ubuntu 12.04.4 LTS","title":"Main Sections"},{"location":"cookbooks/postfix/advanced_setup/","text":"load balancing with HAProxy \u00b6 For SMTP, it is really important to know the client IP, since we use it most of the time through RBL to fight spam. For security purpose as well: we may want to allow only some hosts to use our SMTP relays and block any other clients. Without the proxy protocol, the load-balancer will hide the client IP with its own IP. You would have to maintain whitelists into the load-balancer (which is doable). Thanks to proxy protocol, Postscreen would be aware of the client IP, it means you could maintain lists directly into the MTA. SECURITY \u00b6 To see if an outsider can reach you, run this command: 1 2 telnet relay-test.mail-abuse.org host relay-test.mail-abuse.org When you make this connection, relay-test.mail-abuse.org performs an online relay test of the machine that made the connection. If your ISP (or your own firewall) doesn\u2019t block incoming connections to your box on port 25, then you should see quite a few messages in your log file. 1 2 3 netstat -t -a | grep LISTEN lsof -i tcp:25 Test \u00b6 Now let\u2019s turn our attention to smtp-sink to find out how many messages per second your server can handle from your horrible mass mailing sofware. Postfix has to process each outgoing message even if the server on the other side throws it away (therefore, you can\u2019t use this to test the raw performance of your mass mailer unless you connect your mailer directly to smtp-sink). The following example sets up an SMTP listener on port 25 of localhost: 1 ./smtp-sink -c localhost:25 1000 Now you can run your client tests. If you want to get an idea for how much overhead the network imposes and also get a control experiment to see what the theoretical maximum throughput for a mail server, you can make smtp-source and smtp-sink talk to each other. Open two windows. In the first, start up the dummy server like this: 1 ./smtp-sink -c localhost:25 1000 100 With this in place, start throwing messages at this server with smtp-source in the other window: 1 2 3 4 5 time ./smtp-source -s 20 -l 5120 -m 100 -c -f sender@example.com -t recipient@example.com localhost:25 100 real 0m0.239s user 0m0.000s sys 0m0.040s Install Local DNS server \u00b6 Improve domain lookup and cache","title":"Advanced setup"},{"location":"cookbooks/postfix/advanced_setup/#load-balancing-with-haproxy","text":"For SMTP, it is really important to know the client IP, since we use it most of the time through RBL to fight spam. For security purpose as well: we may want to allow only some hosts to use our SMTP relays and block any other clients. Without the proxy protocol, the load-balancer will hide the client IP with its own IP. You would have to maintain whitelists into the load-balancer (which is doable). Thanks to proxy protocol, Postscreen would be aware of the client IP, it means you could maintain lists directly into the MTA.","title":"load balancing with HAProxy"},{"location":"cookbooks/postfix/advanced_setup/#security","text":"To see if an outsider can reach you, run this command: 1 2 telnet relay-test.mail-abuse.org host relay-test.mail-abuse.org When you make this connection, relay-test.mail-abuse.org performs an online relay test of the machine that made the connection. If your ISP (or your own firewall) doesn\u2019t block incoming connections to your box on port 25, then you should see quite a few messages in your log file. 1 2 3 netstat -t -a | grep LISTEN lsof -i tcp:25","title":"SECURITY"},{"location":"cookbooks/postfix/advanced_setup/#test","text":"Now let\u2019s turn our attention to smtp-sink to find out how many messages per second your server can handle from your horrible mass mailing sofware. Postfix has to process each outgoing message even if the server on the other side throws it away (therefore, you can\u2019t use this to test the raw performance of your mass mailer unless you connect your mailer directly to smtp-sink). The following example sets up an SMTP listener on port 25 of localhost: 1 ./smtp-sink -c localhost:25 1000 Now you can run your client tests. If you want to get an idea for how much overhead the network imposes and also get a control experiment to see what the theoretical maximum throughput for a mail server, you can make smtp-source and smtp-sink talk to each other. Open two windows. In the first, start up the dummy server like this: 1 ./smtp-sink -c localhost:25 1000 100 With this in place, start throwing messages at this server with smtp-source in the other window: 1 2 3 4 5 time ./smtp-source -s 20 -l 5120 -m 100 -c -f sender@example.com -t recipient@example.com localhost:25 100 real 0m0.239s user 0m0.000s sys 0m0.040s","title":"Test"},{"location":"cookbooks/postfix/advanced_setup/#install-local-dns-server","text":"Improve domain lookup and cache","title":"Install Local DNS server"},{"location":"cookbooks/postfix/authentication/","text":"8.1. Install necessary services for authentication \u00b6 1 apt-get install sasl2-bin libsasl2-2 -y 8.2. Correct the permission of smtp authentication related files, \u00b6 1 2 3 4 chown postfix:sasl /var/run/saslauthd chown postfix:sasl /etc/sasldb2 adduser postfix sasl /etc/init.d/postfix restart 8.3. Create configuration files for SMTP authentication \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 cat > /etc/default/saslauthd <<EOF START=yes DESC=\"SASL Authentication Daemon\" NAME=\"saslauthd\" MECHANISMS=\"sasldb\" MECH_OPTIONS=\"\" THREADS=5 OPTIONS=\"-c -m /var/spool/postfix/var/run/saslauthd\" EOF cat > /etc/postfix/sasl/smtpd.conf <<EOF pwcheck_method: saslauthd auxprop_plugin: sasldb saslauthd_path: /var/run/saslauthd/mux mech_list: PLAIN LOGIN CRAM-MD5 DIGEST-MD5 EOF 8.4. Configure postfix to use sasldb for SMTP authentication, \u00b6 1 2 3 4 5 6 7 8 postconf -e \"smtpd_sasl_local_domain=pronostic-facile.fr\" postconf -e \"smtpd_sasl_auth_enable=yes\" postconf -e \"smtpd_sasl_path=smtpd\" postconf -e \"smtpd_sasl_tls_security_options= noanonymous, noplaintext\" postconf -e \"broken_sasl_auth_clients=yes\" /etc/init.d/saslauthd restart /etc/init.d/postfix restart 8.5. Create email user \u00b6 1 2 3 saslpasswd2 -c -u pronostic-facile.fr -f /etc/sasldb2 contact Password: 6523uu3FuWooM22 8.6. Testing \u00b6 Create password hash 1 perl -MMIME::Base64 -e 'print encode_base64(\"\\000contact\\@pronostic-facile.fr\\0006523uu3FuWooM22\");'dXNlcjEAdXNlcjEAWmRFeG1ocGRiclBsbw== Send test email 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 telnet 0 25 Trying 0.0.0.0... Connected to 0. Escape character is '^]'. 220 pronostic-facile.fr ESMTP Postfix (Ubuntu) EHLO pronostic-facile.fr 250-pronostic-facile.fr 250-PIPELINING 250-SIZE 10240000 250-VRFY 250-ETRN 250-STARTTLS 250-AUTH PLAIN LOGIN CRAM-MD5 DIGEST-MD5 250-AUTH=PLAIN LOGIN CRAM-MD5 DIGEST-MD5 250-ENHANCEDSTATUSCODES 250-8BITMIME 250 DSN AUTH PLAIN AGNvbnRhY3RAcHJvbm9zdGljLWZhY2lsZS5mcgA2NTIzdXUzRnVXb29NMjI= 235 2.7.0 Authentication successful MAIL FROM: contact@pronostic-facile.fr 250 2.1.0 Ok RCPT TO: rnldpj@gmail.com 250 2.1.5 Ok DATA 354 End data with <CR><LF>.<CR><LF> Subject: Testing EMAIL This is a testing. Plz ignore. . 250 2.0.0 Ok: queued as CDC8A4095F 421 4.4.2 pronostic-facile.fr Error: timeout exceeded Connection closed by foreign host.","title":"Authentication"},{"location":"cookbooks/postfix/authentication/#81-install-necessary-services-for-authentication","text":"1 apt-get install sasl2-bin libsasl2-2 -y","title":"8.1. Install necessary services for authentication"},{"location":"cookbooks/postfix/authentication/#82-correct-the-permission-of-smtp-authentication-related-files","text":"1 2 3 4 chown postfix:sasl /var/run/saslauthd chown postfix:sasl /etc/sasldb2 adduser postfix sasl /etc/init.d/postfix restart","title":"8.2. Correct the permission of smtp authentication related files,"},{"location":"cookbooks/postfix/authentication/#83-create-configuration-files-for-smtp-authentication","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 cat > /etc/default/saslauthd <<EOF START=yes DESC=\"SASL Authentication Daemon\" NAME=\"saslauthd\" MECHANISMS=\"sasldb\" MECH_OPTIONS=\"\" THREADS=5 OPTIONS=\"-c -m /var/spool/postfix/var/run/saslauthd\" EOF cat > /etc/postfix/sasl/smtpd.conf <<EOF pwcheck_method: saslauthd auxprop_plugin: sasldb saslauthd_path: /var/run/saslauthd/mux mech_list: PLAIN LOGIN CRAM-MD5 DIGEST-MD5 EOF","title":"8.3. Create configuration files for SMTP authentication"},{"location":"cookbooks/postfix/authentication/#84-configure-postfix-to-use-sasldb-for-smtp-authentication","text":"1 2 3 4 5 6 7 8 postconf -e \"smtpd_sasl_local_domain=pronostic-facile.fr\" postconf -e \"smtpd_sasl_auth_enable=yes\" postconf -e \"smtpd_sasl_path=smtpd\" postconf -e \"smtpd_sasl_tls_security_options= noanonymous, noplaintext\" postconf -e \"broken_sasl_auth_clients=yes\" /etc/init.d/saslauthd restart /etc/init.d/postfix restart","title":"8.4. Configure postfix to use sasldb for SMTP authentication,"},{"location":"cookbooks/postfix/authentication/#85-create-email-user","text":"1 2 3 saslpasswd2 -c -u pronostic-facile.fr -f /etc/sasldb2 contact Password: 6523uu3FuWooM22","title":"8.5. Create email user"},{"location":"cookbooks/postfix/authentication/#86-testing","text":"Create password hash 1 perl -MMIME::Base64 -e 'print encode_base64(\"\\000contact\\@pronostic-facile.fr\\0006523uu3FuWooM22\");'dXNlcjEAdXNlcjEAWmRFeG1ocGRiclBsbw== Send test email 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 telnet 0 25 Trying 0.0.0.0... Connected to 0. Escape character is '^]'. 220 pronostic-facile.fr ESMTP Postfix (Ubuntu) EHLO pronostic-facile.fr 250-pronostic-facile.fr 250-PIPELINING 250-SIZE 10240000 250-VRFY 250-ETRN 250-STARTTLS 250-AUTH PLAIN LOGIN CRAM-MD5 DIGEST-MD5 250-AUTH=PLAIN LOGIN CRAM-MD5 DIGEST-MD5 250-ENHANCEDSTATUSCODES 250-8BITMIME 250 DSN AUTH PLAIN AGNvbnRhY3RAcHJvbm9zdGljLWZhY2lsZS5mcgA2NTIzdXUzRnVXb29NMjI= 235 2.7.0 Authentication successful MAIL FROM: contact@pronostic-facile.fr 250 2.1.0 Ok RCPT TO: rnldpj@gmail.com 250 2.1.5 Ok DATA 354 End data with <CR><LF>.<CR><LF> Subject: Testing EMAIL This is a testing. Plz ignore. . 250 2.0.0 Ok: queued as CDC8A4095F 421 4.4.2 pronostic-facile.fr Error: timeout exceeded Connection closed by foreign host.","title":"8.6. Testing"},{"location":"cookbooks/postfix/bounce/","text":"Soft vs Hard Specify postfix to send all bounce emails to email address \u2018 bounce@pronostic-facile.fr \u2018 in /etc/postfix/main.cf 1 2 3 4 postconf -e \"notify_classes=bounce,resource,software\" postconf -e \"bounce_notice_recipient=bounce@pronostic-facile.fr\" postconf -e \"transport_maps=regexp:/etc/postfix/transport\" postfix reload As we want to bounce emails to go to \u2018 bounce@pronostic-facile.fr \u2018 in cpanel server, we need to add the following in /etc/postfix/transport 1 /bounce.*/ smtp:ASPMX.L.GOOGLE.COM:25 To forward to google apps and not local in /etc/postfix/transport 1 /pronostic-facile\\.fr/ relay:[ASPMX.L.GOOGLE.COM]","title":"Bounce"},{"location":"cookbooks/postfix/conclusion/","text":"HELO check helocheck@cbl.abuseat.org http://www.mail-tester.com/ avoid broken links, multi domains links http://www.kitterman.com/spf/validate.html https://www.blacklistmaster.com http://postmaster.free.fr/ Big companies can send millions emails a day without trick, just following good practices double opt-in (give email and validate) bounce management domain configuration; from; links keywords If you dont want to manage everything; we are doing it for you with MAILCHITA, first grade service for serious emailers. Segregate IPs Don\u2019t send bulk/marketing email from the same IPs you use to send user mail, transactional mail, alerts, etc. Each IP you send from has a reputation. By segregating your IPs according to function, you help ensure that your mail receives the best delivery possible. If you send both promotional mail and transactional mail relating to your organization, we recommend separating mail by purpose as much as possible. You can do this by: Using separate email addresses for each function. Sending mail from different domains and/or IP addresses for each function. Update: For future reference, the problem was in /etc/mailname which listed a name that wasn\u2019t in the mydestinations list of postfix. This caused all mails to be considered foreign and the mail bypassed /etc/aliases processing \u2003 Test Test Test http://www.facilemail.fr/ http://www.port25.com/support/authentication-center/email-verification/ http://isnotspam.com/ http://spamscorechecker.com/ https://www.dnsstuff.com/member/register/ http://www.dnsgoodies.com/ http://www.debouncer.com/mx-lookup http://dnscheck.pingdom.com/?domain=mailing.pronostic-facile.fr http://protodave.com/security/checking-your-dkim-dns-record/ http://mxtoolbox.com/SuperTool.aspx?action=smtp%3a188.226.182.49&run=toolpage# Resources mailbang mailchita mailintouch","title":"Conclusion"},{"location":"cookbooks/postfix/dkim_spf/","text":"2.1. Install dkim related packages \u00b6 1 apt-get install opendkim opendkim-tools 2.2. Configure DKIM \u00b6 Copy paste the following into a text file and save as a bash script. You can change the variables \u201cDOMAIN\u201d and \u201cSELECTOR\u201d to the one you choose depending upon the requirement. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 DOMAIN=\"pronostic-facile.fr\" SELECTOR=\"default\" mkdir -p /etc/opendkim/keys/${DOMAIN} opendkim-genkey -D /etc/opendkim/keys/${DOMAIN}/ -d ${DOMAIN} -s ${SELECTOR} chown -R opendkim:opendkim /etc/opendkim/keys/${DOMAIN} cat > /etc/opendkim/dkim-InternalHosts.txt << EOF ${DOMAIN} `hostname` `ifconfig |grep \"inet addr:\"|awk '{print $2}'|cut -d: -f2|uniq` EOF cat > /etc/opendkim.conf << EOF PidFile /var/run/opendkim/opendkim.pid Syslog yes Domain ${DOMAIN} KeyFile /etc/opendkim/keys/${DOMAIN}/${SELECTOR}.private Selector ${SELECTOR} SyslogSuccess yes LogWhy yes UserID opendkim:opendkim Umask 002 Canonicalization relaxed/simple AutoRestart yes Background yes DNSTimeout 10 Mode sv SignatureAlgorithm rsa-sha256 SubDomains no X-Header no Statistics /var/log/dkim-filter/dkim-stats InternalHosts /etc/opendkim/dkim-InternalHosts.txt EOF cat > /etc/default/opendkim << EOF SOCKET=\"inet:8891@localhost\" EOF postconf -e smtpd_milters=\"inet:localhost:8891\" postconf -e non_smtpd_milters=\"inet:localhost:8891\" service opendkim restart service postfix restart 2.3. Update DNS \u00b6 Add server ip\u2019s 144.76.113.170 & 144.76.113.185 to spf record of domain. SPF and TXT records: 1 \"v=spf1 A include:aspmx.googlemail.com +ip4:5.9.20.211 ip4:144.76.113.170 ip4:144.76.113.185 include:_spf.google.com include:spf.mailjet.com include:helpscoutemail.com include:mailgun.org ~all\" Publish the contents of file /etc/opendkim/keys/pronostic-facile.fr/default.txt as a TXT record in the dns of domain. 1 2 3 4 5 root@Ubuntu-1204-precise-64-minimal ~ # cat /etc/opendkim/keys/pronostic-facile.fr/default.txt default._domainkey IN TXT \"v=DKIM1; k=rsa; p=MIGfMA0GCSqGSIb3DQEBAQU...yxVM1VK9Ex+GBgO4QIDAQAB\" ; ----- DKIM key default for pronostic-facile.fr root@Ubuntu-1204-precise-64-minimal ~ # Ref: https://help.ubuntu.com/community/Postfix/DKIM http://askubuntu.com/questions/134725/setup-dkim-domainkeys-for-ubuntu-postfix-and-mailman","title":"Dkim spf"},{"location":"cookbooks/postfix/dkim_spf/#21-install-dkim-related-packages","text":"1 apt-get install opendkim opendkim-tools","title":"2.1. Install dkim related packages"},{"location":"cookbooks/postfix/dkim_spf/#22-configure-dkim","text":"Copy paste the following into a text file and save as a bash script. You can change the variables \u201cDOMAIN\u201d and \u201cSELECTOR\u201d to the one you choose depending upon the requirement. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 DOMAIN=\"pronostic-facile.fr\" SELECTOR=\"default\" mkdir -p /etc/opendkim/keys/${DOMAIN} opendkim-genkey -D /etc/opendkim/keys/${DOMAIN}/ -d ${DOMAIN} -s ${SELECTOR} chown -R opendkim:opendkim /etc/opendkim/keys/${DOMAIN} cat > /etc/opendkim/dkim-InternalHosts.txt << EOF ${DOMAIN} `hostname` `ifconfig |grep \"inet addr:\"|awk '{print $2}'|cut -d: -f2|uniq` EOF cat > /etc/opendkim.conf << EOF PidFile /var/run/opendkim/opendkim.pid Syslog yes Domain ${DOMAIN} KeyFile /etc/opendkim/keys/${DOMAIN}/${SELECTOR}.private Selector ${SELECTOR} SyslogSuccess yes LogWhy yes UserID opendkim:opendkim Umask 002 Canonicalization relaxed/simple AutoRestart yes Background yes DNSTimeout 10 Mode sv SignatureAlgorithm rsa-sha256 SubDomains no X-Header no Statistics /var/log/dkim-filter/dkim-stats InternalHosts /etc/opendkim/dkim-InternalHosts.txt EOF cat > /etc/default/opendkim << EOF SOCKET=\"inet:8891@localhost\" EOF postconf -e smtpd_milters=\"inet:localhost:8891\" postconf -e non_smtpd_milters=\"inet:localhost:8891\" service opendkim restart service postfix restart","title":"2.2. Configure DKIM"},{"location":"cookbooks/postfix/dkim_spf/#23-update-dns","text":"Add server ip\u2019s 144.76.113.170 & 144.76.113.185 to spf record of domain. SPF and TXT records: 1 \"v=spf1 A include:aspmx.googlemail.com +ip4:5.9.20.211 ip4:144.76.113.170 ip4:144.76.113.185 include:_spf.google.com include:spf.mailjet.com include:helpscoutemail.com include:mailgun.org ~all\" Publish the contents of file /etc/opendkim/keys/pronostic-facile.fr/default.txt as a TXT record in the dns of domain. 1 2 3 4 5 root@Ubuntu-1204-precise-64-minimal ~ # cat /etc/opendkim/keys/pronostic-facile.fr/default.txt default._domainkey IN TXT \"v=DKIM1; k=rsa; p=MIGfMA0GCSqGSIb3DQEBAQU...yxVM1VK9Ex+GBgO4QIDAQAB\" ; ----- DKIM key default for pronostic-facile.fr root@Ubuntu-1204-precise-64-minimal ~ # Ref: https://help.ubuntu.com/community/Postfix/DKIM http://askubuntu.com/questions/134725/setup-dkim-domainkeys-for-ubuntu-postfix-and-mailman","title":"2.3. Update DNS"},{"location":"cookbooks/postfix/domainkeys/","text":"3.1. Install dk-filter milter package \u00b6 1 apt-get install dk-filter 3.2. Configuration \u00b6 Copy paste the following into a text file and save as a bash script. You can change the variables \u201cDOMAIN\u201d and \u201cSELECTOR\u201d to the one you choose depending upon the requirement. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 DOMAIN=\"pronostic-facile.fr\" SELECTOR=\"mail\" mkdir -p /etc/domainkeys/${DOMAIN}/ cd /etc/domainkeys/${DOMAIN}/ openssl genrsa -out private.key 1024 openssl rsa -in private.key -out public.key -pubout -outform PEM cat > /etc/domainkeys/trustlist.txt << EOF ${DOMAIN} `hostname` `ifconfig |grep \"inet addr:\"|awk '{print $2}'|cut -d: -f2|uniq` EOF cat > /etc/default/dk-filter << EOF DAEMON_OPTS=\"-l\" DAEMON_OPTS=\"$DAEMON_OPTS -d ${DOMAIN} -s /etc/domainkeys/${DOMAIN}/private.key -S ${SELECTOR} -i /etc/domainkeys/trustlist.txt\" SOCKET=\"inet:8892@localhost\" EOF postconf -e smtpd_milters=\"inet:localhost:8891,inet:localhost:8892\" postconf -e non_smtpd_milters=\"inet:localhost:8891,inet:localhost:8892\" service dk-filter restart service postfix restart 3.3. Update DNS \u00b6 Publish the following DNS records. The public key is taken from file /etc/domainkeys/pronostic-facile.fr/public.key . 1 2 3 _domainkey.pronostic-facile.fr. IN TXT \"t=y; o=~; mail._domainkey.pronostic-facile.fr. IN TXT \"k=rsa; t=y; p=MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCbG2dfmfhS2g5T5bKdzhh9oAxKHEGVJmOXcGT7bcSWsDKxXL6SWNaCl4HzHoPHVnRfjZYyNtehJ19FAupSlGme7wJNqQI6GTXAvApUYEbjKbffLfGresB6quuy//xjbK2H7J01apdvYHzDdmenwGVmufPoK4ASokm35plkXfXGVwIDAQAB\" Ref: DomainKeys on Ubuntu","title":"Domainkeys"},{"location":"cookbooks/postfix/domainkeys/#31-install-dk-filter-milter-package","text":"1 apt-get install dk-filter","title":"3.1. Install dk-filter milter package"},{"location":"cookbooks/postfix/domainkeys/#32-configuration","text":"Copy paste the following into a text file and save as a bash script. You can change the variables \u201cDOMAIN\u201d and \u201cSELECTOR\u201d to the one you choose depending upon the requirement. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 DOMAIN=\"pronostic-facile.fr\" SELECTOR=\"mail\" mkdir -p /etc/domainkeys/${DOMAIN}/ cd /etc/domainkeys/${DOMAIN}/ openssl genrsa -out private.key 1024 openssl rsa -in private.key -out public.key -pubout -outform PEM cat > /etc/domainkeys/trustlist.txt << EOF ${DOMAIN} `hostname` `ifconfig |grep \"inet addr:\"|awk '{print $2}'|cut -d: -f2|uniq` EOF cat > /etc/default/dk-filter << EOF DAEMON_OPTS=\"-l\" DAEMON_OPTS=\"$DAEMON_OPTS -d ${DOMAIN} -s /etc/domainkeys/${DOMAIN}/private.key -S ${SELECTOR} -i /etc/domainkeys/trustlist.txt\" SOCKET=\"inet:8892@localhost\" EOF postconf -e smtpd_milters=\"inet:localhost:8891,inet:localhost:8892\" postconf -e non_smtpd_milters=\"inet:localhost:8891,inet:localhost:8892\" service dk-filter restart service postfix restart","title":"3.2. Configuration"},{"location":"cookbooks/postfix/domainkeys/#33-update-dns","text":"Publish the following DNS records. The public key is taken from file /etc/domainkeys/pronostic-facile.fr/public.key . 1 2 3 _domainkey.pronostic-facile.fr. IN TXT \"t=y; o=~; mail._domainkey.pronostic-facile.fr. IN TXT \"k=rsa; t=y; p=MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCbG2dfmfhS2g5T5bKdzhh9oAxKHEGVJmOXcGT7bcSWsDKxXL6SWNaCl4HzHoPHVnRfjZYyNtehJ19FAupSlGme7wJNqQI6GTXAvApUYEbjKbffLfGresB6quuy//xjbK2H7J01apdvYHzDdmenwGVmufPoK4ASokm35plkXfXGVwIDAQAB\" Ref: DomainKeys on Ubuntu","title":"3.3. Update DNS"},{"location":"cookbooks/postfix/installation/","text":"1.1. Install postfix and opendkim \u00b6 apt-get install postfix opendkim -y 1.2. Modify postfix configuration \u00b6 hint: don\u2019t set \u2018mydestination=pronostic-facile.fr\u2019 else any bounce or postmaster will be delivred localy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 postconf -e mydomain=pronostic-facile.fr postconf -e inet_protocols=ipv4 postconf -e myhostname=pronostic-facile.fr postconf -e smtpd_sasl_local_domain=pronostic-facile.fr postconf -e smtpd_sasl_auth_enable=yes postconf -e smtpd_sasl_tls_security_options=\"noanonymous, noplaintext\" postconf -e broken_sasl_auth_clients=yes postconf -e smtpd_recipient_restrictions=\"permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination\" postconf -e milter_default_action=accept postconf -e milter_protocol=2 smtp_helo_name = pronostic-facile.fr default_destination_concurrency_limit = 20 address_verify_map = memcache:/etc/postfix/verify-memcache.cf address_verify_cache_cleanup_interval = 0 myhostname : This is the hostname of your machine. But don\u2019t put the full hostname. If your machine hostname is mail.mydomain.com you will only use mydomain. mydestination : This parameter specifies what destinations this machine will deliver locally. The default is: mydestination = $myhostname localhost.$mydomain localhost 1.3. Submission (port: 587) configuration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 submission inet n \u2013 n \u2013 \u2013 smtpd -o smtpd_tls_security_level=encrypt -o smtpd_sasl_auth_enable=yes smtp inet n - n - - smtpd -v submission inet n - n - - smtpd -o smtpd_etrn_restrictions=reject -o smtpd_sasl_type=dovecot -o smtpd_sasl_path=private/auth -o smtpd_sasl_auth_enable=yes -o smtpd_reject_unlisted_sender=yes -o smtpd_recipient_restrictions=permit_mynetworks,permit_sasl_authenticated,reject 1.4. Restart postfix \u00b6 1 service postfix restart 1.5. Keep on time \u00b6 Add ntp time-date (very important to maintain the date-time stamp when dealing with emails) 1 2 3 ntpdate ntp.pool.org service ntpd start chkconfig ntpd on","title":"Installation"},{"location":"cookbooks/postfix/installation/#11-install-postfix-and-opendkim","text":"apt-get install postfix opendkim -y","title":"1.1. Install postfix and opendkim"},{"location":"cookbooks/postfix/installation/#12-modify-postfix-configuration","text":"hint: don\u2019t set \u2018mydestination=pronostic-facile.fr\u2019 else any bounce or postmaster will be delivred localy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 postconf -e mydomain=pronostic-facile.fr postconf -e inet_protocols=ipv4 postconf -e myhostname=pronostic-facile.fr postconf -e smtpd_sasl_local_domain=pronostic-facile.fr postconf -e smtpd_sasl_auth_enable=yes postconf -e smtpd_sasl_tls_security_options=\"noanonymous, noplaintext\" postconf -e broken_sasl_auth_clients=yes postconf -e smtpd_recipient_restrictions=\"permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination\" postconf -e milter_default_action=accept postconf -e milter_protocol=2 smtp_helo_name = pronostic-facile.fr default_destination_concurrency_limit = 20 address_verify_map = memcache:/etc/postfix/verify-memcache.cf address_verify_cache_cleanup_interval = 0 myhostname : This is the hostname of your machine. But don\u2019t put the full hostname. If your machine hostname is mail.mydomain.com you will only use mydomain. mydestination : This parameter specifies what destinations this machine will deliver locally. The default is: mydestination = $myhostname localhost.$mydomain localhost","title":"1.2. Modify postfix configuration"},{"location":"cookbooks/postfix/installation/#13-submission-port-587-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 submission inet n \u2013 n \u2013 \u2013 smtpd -o smtpd_tls_security_level=encrypt -o smtpd_sasl_auth_enable=yes smtp inet n - n - - smtpd -v submission inet n - n - - smtpd -o smtpd_etrn_restrictions=reject -o smtpd_sasl_type=dovecot -o smtpd_sasl_path=private/auth -o smtpd_sasl_auth_enable=yes -o smtpd_reject_unlisted_sender=yes -o smtpd_recipient_restrictions=permit_mynetworks,permit_sasl_authenticated,reject","title":"1.3. Submission (port: 587) configuration"},{"location":"cookbooks/postfix/installation/#14-restart-postfix","text":"1 service postfix restart","title":"1.4. Restart postfix"},{"location":"cookbooks/postfix/installation/#15-keep-on-time","text":"Add ntp time-date (very important to maintain the date-time stamp when dealing with emails) 1 2 3 ntpdate ntp.pool.org service ntpd start chkconfig ntpd on","title":"1.5. Keep on time"},{"location":"cookbooks/postfix/ip_rotating/","text":"7.1. IPTable \u00b6 Add the following iptable rules for ip rotation 1 2 3 iptables -t nat -I POSTROUTING -m state --state NEW -p tcp --dport 25 -o eth0 -m statistic --mode nth --every 2 --packet 1 -j SNAT --to-source 144.76.113.170 iptables -t nat -I POSTROUTING -m state --state NEW -p tcp --dport 25 -o eth0 -m statistic --mode nth --every 2 --packet 1 -j SNAT --to-source 144.76.113.185 7.2. Take backup of current iptable rules \u00b6 1 iptables-save > /etc/network/iptablerules.txt 7.3. Add the following line in network service configuration file(ie, /etc/network/interfaces ), \u00b6 1 post-up iptables-restore < /etc/network/iptablerules.txt eg: 1 2 3 4 5 6 7 8 9 10 auto eth0 iface eth0 inet static address 144.76.113.170 broadcast 144.76.113.191 netmask 255.255.255.224 gateway 144.76.113.161 post-up iptables-restore < /etc/network/iptablerules.txt # default route to access subnet up route add -net 144.76.113.160 netmask 255.255.255.224 gw 144.76.113.161 eth0 smtp_bind_address directive to use multiple IPs and ip rotation can be achieved with route balancing.","title":"Ip rotating"},{"location":"cookbooks/postfix/ip_rotating/#71-iptable","text":"Add the following iptable rules for ip rotation 1 2 3 iptables -t nat -I POSTROUTING -m state --state NEW -p tcp --dport 25 -o eth0 -m statistic --mode nth --every 2 --packet 1 -j SNAT --to-source 144.76.113.170 iptables -t nat -I POSTROUTING -m state --state NEW -p tcp --dport 25 -o eth0 -m statistic --mode nth --every 2 --packet 1 -j SNAT --to-source 144.76.113.185","title":"7.1. IPTable"},{"location":"cookbooks/postfix/ip_rotating/#72-take-backup-of-current-iptable-rules","text":"1 iptables-save > /etc/network/iptablerules.txt","title":"7.2. Take backup of current iptable rules"},{"location":"cookbooks/postfix/ip_rotating/#73-add-the-following-line-in-network-service-configuration-fileie-etcnetworkinterfaces","text":"1 post-up iptables-restore < /etc/network/iptablerules.txt eg: 1 2 3 4 5 6 7 8 9 10 auto eth0 iface eth0 inet static address 144.76.113.170 broadcast 144.76.113.191 netmask 255.255.255.224 gateway 144.76.113.161 post-up iptables-restore < /etc/network/iptablerules.txt # default route to access subnet up route add -net 144.76.113.160 netmask 255.255.255.224 gw 144.76.113.161 eth0 smtp_bind_address directive to use multiple IPs and ip rotation can be achieved with route balancing.","title":"7.3. Add the following line in network service configuration file(ie, /etc/network/interfaces ),"},{"location":"cookbooks/postfix/monitoring/","text":"Mailgraph And pflogsumm \u00b6 Want to support HowtoForge? Become a subscriber! Submitted by falko (Contact Author) (Forums) on Mon, 2006-07-03 15:58. :: 4 Fedora Core 5 4.1 Mailgraph There\u2019s no Mailgraph package available for Fedora Core 5, so we must install it manually. First, we need to install the prerequsities that Mailgraph requires: 1 yum install rrdtool rrdtool-perl perl-File-Tail Then we download the Mailgraph sources and copy the Mailgraph scripts to the appropriate locations: 1 cd /tmp\u2028wget http://people.ee.ethz.ch/~dws/software/mailgraph/pub/mailgraph-1.12.tar.gz\u2028tar xvfz mailgraph-1.12.tar.gz\u2028cd mailgraph-1.12\u2028mv mailgraph.pl /usr/local/bin/mailgraph.pl\u2028mv mailgraph-init /etc/init.d/mailgraph Now we must adjust the Mailgraph init script /etc/init.d/mailgraph: 1 vi /etc/init.d/mailgraph On Fedora, the Postfix mail log is /var/log/maillog, so we change 1 2 MAIL_LOG=/var/log/syslog MAIL_LOG=/var/log/maillog Then we add another variable to /etc/init.d/mailgraph, IGNORE_LOCALHOST. If you have integrated a content filter like amavisd into Postfix, add this line 1 IGNORE_LOCALHOST=\"--ignore-localhost\" to the block where the variables like MAIL_LOG are defined. If you don\u2019t use a content filter, add this line instead: 1 IGNORE_LOCALHOST=\"\" In both cases, change 1 2 3 4 nice -19 $MAILGRAPH_PL -l $MAIL_LOG -d \\ --daemon-pid=$PID_FILE --daemon-rrd=$RRD_DIR nice -19 $MAILGRAPH_PL -l $MAIL_LOG -d \\ --daemon-pid=$PID_FILE --daemon-rrd=$RRD_DIR $IGNORE_LOCALHOST So the final script should look like this (in this case, with \u2013ignore-localhost enabled): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #!/bin/sh # $Id: mailgraph-init,v 1.4 2005/06/13 11:23:22 dws Exp $ # example init script for mailgraph # # chkconfig: 2345 82 28 # description: mailgraph postfix log grapher. # # processname: mailgraph.pl # pidfile: /var/run/mailgraph.pid PATH=/bin:/usr/bin MAILGRAPH_PL=/usr/local/bin/mailgraph.pl MAIL_LOG=/var/log/maillog PID_FILE=/var/run/mailgraph.pid RRD_DIR=/var/lib IGNORE_LOCALHOST=\"--ignore-localhost\" case \"$1\" in 'start') echo \"Starting mail statistics grapher: mailgraph\"; nice -19 $MAILGRAPH_PL -l $MAIL_LOG -d \\ --daemon-pid=$PID_FILE --daemon-rrd=$RRD_DIR $IGNORE_LOCALHOST ;; 'stop') echo \"Stopping mail statistics grapher: mailgraph\"; if [ -f $PID_FILE ]; then kill `cat $PID_FILE` rm $PID_FILE else echo \"mailgraph not running\"; fi ;; *) echo \"Usage: $0 { start | stop }\" exit 1 ;; esac exit 0 Next we make the script executable, create the appropriate system startup links and start Mailgraph: 1 chmod 755 /etc/init.d/mailgraph\u2028chkconfig --levels 235 mailgraph on\u2028/etc/init.d/mailgraph start Still in the /tmp/mailgraph-1.12 directory, we move mailgraph.cgi to our cgi-bin directory: 1 mv mailgraph.cgi /var/www/www.example.com/cgi-bin/ Now we open the file and adjust the locations of the two Mailgraph databases. 1 vi /var/www/www.example.com/cgi-bin/mailgraph.cgi Change 1 2 3 4 my $rrd = 'mailgraph.rrd'; # path to where the RRD database is my $rrd_virus = 'mailgraph_virus.rrd'; # path to where the Virus RRD database is my $rrd = '/var/lib/mailgraph.rrd'; # path to where the RRD database is my $rrd_virus = '/var/lib/mailgraph_virus.rrd'; # path to where the Virus RRD database is Then we make the script executable: 1 chmod 755 /var/www/www.example.com/cgi-bin/mailgraph.cgi If you use suExec for the www.example.com web site, you must chown mailgraph.cgi to the appropriate owner and group. Now direct your browser to http://www.example.com/cgi-bin/mailgraph.cgi , and you should see some graphs. Of course, there must be some emails going through your system before you see the first results, so be patient. 4.2 pflogsumm \u00b6 The steps differ only slightly from those on Debian and Ubuntu. The main difference is that Postfix logs to /var/log/maillog on Fedora instead of /var/log/mail.log (Debian/Ubuntu) (pay attention to the dot!). First we install pflogsumm: 1 yum install postfix-pflogsumm We want pflogsumm to be run by a cron job each day and send the report to postmaster@example.com . Therefore we must configure our system that it writes one mail log file for 24 hours, and afterwards starts the next mail log so that we can feed the old mail log to pflogsumm. Therefore we configure logrotate (that\u2019s the program that rotates our system\u2019s log files) like this: open /etc/logrotate.conf and append the following stanza to it, after the line # system-specific logs may be configured here: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 vi /etc/logrotate.conf /var/log/maillog { missingok daily rotate 7 create compress start 0 } Also change /etc/logrotate.d/syslog vi /etc/logrotate.d/syslog /var/log/messages /var/log/secure /var/log/maillog /var/log/spooler /var/log/boot.log /var/log/cron { sharedscripts postrotate /bin/kill -HUP `cat /var/run/syslogd.pid 2> /dev/null` 2> /dev/null || true endscript } /var/log/messages /var/log/secure /var/log/spooler /var/log/boot.log /var/log/cron { sharedscripts postrotate /bin/kill -HUP `cat /var/run/syslogd.pid 2> /dev/null` 2> /dev/null || true endscript } There\u2019s a logrotate script in /etc/cron.daily. This script is called everyday between 06:00h and 07:00h. With the configuration we just made, it will copy the current Postfix log /var/log/maillog to /var/log/maillog.0 and compress it, and the compressed file will be /var/log/maillog.0.gz. It will also create a new, empty /var/log/maillog to which Postfix can log for the next 24 hours. Now we create the script /usr/local/sbin/postfix_report.sh which invokes pflogsumm and makes it send the report to postmaster@example.com : 1 2 3 4 5 6 7 8 9 vi /usr/local/sbin/postfix_report.sh #!/bin/sh PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin gunzip /var/log/maillog.0.gz pflogsumm /var/log/maillog.0 | formail -c -I\"Subject: Mail Statistics\" -I\"From: pflogsumm@localhost\" -I\"To: postmaster@example.com\" -I\"Received: from www.example.com ([192.168.0.100])\" | sendmail postmaster@example.com gzip /var/log/maillog.0 exit 0 We must make this script executable: 1 chmod 755 /usr/local/sbin/postfix_report.sh Then we create a cron job which calls the script everyday at 07:00h: crontab -e 0 7 * * * /usr/local/sbin/postfix_report.sh &> /dev/null This will send the report to postmaster@example.com . mailgraph statistics for postfix running on nginx I\u2019m using postfix as my mail server. In order to get nice graphical overview about the server activity I\u2019m using mailgraph.\u2028Mailgraph is a cgi script written in perl. It uses rrdtool to produce daily, weekly, monthly and yearly graphs of received/sent and bounced/rejected mail. Installing mailgraph on debian is as easy as running: 1 aptitude install mailgraph The configuration takes place in /etc/default/mailgraph. Make sure to modify it according to your mail setup. In order to run in on nginx server, one needs to install fcgiwrap and spawn-fcgi first. Nothing simpler than that: 1 aptitude install fcgiwrap spawn-fcgi Configuring nginx to use fcgiwrap requires the following: Creation of the /etc/nginx/conf.d/fcgiwrap.conf file with the following content: 1 2 3 4 5 6 7 8 9 . upstream fcgiwrap { . server unix:/var/run/fcgiwrap.socket; . } . Instructions to the nginx, to pass the cgi scripts to fcgiwrap (done in the server section for the virtual host): . location ~ \\.cgi$ { . root /usr/lib/cgi-bin; . include /etc/nginx/fastcgi_params; . fastcgi_pass fcgiwrap; . } The result for weekly statistics looks like shown below: Simple Bash Monitoring \u00b6 You can monitor the queues with a simple bashscript: 1 #!/bin/bash # 20.06.2011 - JJaritsch @ ANEXIA Internetdienstleistungs GmbH # jj@anexia.at queuelength=`/usr/sbin/postqueue -p | tail -n1 | awk '{print $5}'` queuecount=`echo $queuelength | grep \"[0-9]\"` if [ \"$queuecount\" == \"\" ]; then echo 0; else echo ${queuelength}; fi exit 35 Save this script and make it executable (0755 is enough) for the snmpd user. The next step is to add the following line to your snmpd.conf: 1 exec postqueue /path/to/your/snmp_monitor_postqueue.sh If you want to use sudo, you can add this line: 1 exec postqueue /usr/bin/sudo /path/to/your/snmp_monitor_postqueue.sh In case of sudo you also have to add the following to your sudoers file (so there is no auth required to execute this script): 1 snmp ALL=(ALL) NOPASSWD: /path/to/your/snmp_monitor_postqueue.sh Reload your snmpd - you will find the count-result in .1.3.6.1.4.1.2021.8.1.101.* (for example in .1.3.6.1.4.1.2021.8.1.101.1 if you have no other additional lines in the snmpd.conf). Another monitoring Bash \u2013 MSMTP \u00b6 In addition to Bryan Rehbein\u2019s answer above, here\u2019s a script I use to monitor postfix queue lengths. All it does is send an email alert once a queue grows beyond X messages in size. The alert is sent using msmtp (a tiny command line smtp client) so it bypasses the local postfix installation (which you can\u2019t rely on to get your alert out in a timely fashion if its queues are growing\u2026) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #!/bin/bash # # Postfix queue length monitoring script (requires msmtp) # # This script checks the active, incoming, deferred and maildrop postfix queue directories. # # If the number of messages in any of these directories is more than $MAX_QUEUE_LENGTH, # the script will generate an alert email and send it using msmtp. We use msmtp so that # we can bypass the local postfix installation (since if the queues are getting big, # the alert email may not be sent in time to catch the problem). # ######################################################## # # SET SCRIPT VARS ######################################################## # # Path to msmtp binary (e.g. /usr/bin/msmtp on Debian systems) MSMTP=/usr/bin/msmtp # Remote mail host (this is the mail server msmtp will use to send the alert. It should NOT be the local postfix installation) MAILHOST=backup.mailserver.com # Remote mail port MAILPORT=25 # Mail protocol MAILPROTO=smtp # Fully qualified domain name of local postfix installation DOMAIN=primary.mailserver.com # From address MAILFROM=postmaster@mailserver.com # Recipient (this address should not route to the local postfix installation, for obvious reasons) MAILTO=\"alerts@anotherdomain.com\" # Email subject MAILSUBJECT=\"Postfix queue length alert for ${DOMAIN}\" # MSMTP log file LOGFILE=/var/log/msmtp.log # Root of the postfix queue dirs (e.g. /var/spool/postfix on Debian systems). Note: no trailing slash. QUEUEDIR_ROOT=\"/var/spool/postfix\" # Max queue length (if there are more messages in a queue than this number, we will send an alert) MAX_QUEUE_LENGTH=10 ######################################################### # SCRIPT LOGIC STARTS HERE ######################################################### # Check msmtp binary exists if [ ! -f ${MSMTP} ] then echo \"Cannot find ${MSMTP}. Exiting.\" exit 1 fi # Get the number of messages sitting in each postfix queue directory Q_ACTIVE=$(find ${QUEUEDIR_ROOT}/active -type f | wc -l) Q_INCOMING=$(find ${QUEUEDIR_ROOT}/incoming -type f | wc -l) Q_DEFERRED=$(find ${QUEUEDIR_ROOT}/deferred -type f | wc -l) Q_MAILDROP=$(find ${QUEUEDIR_ROOT}/maildrop -type f | wc -l) # If any of these queues contain more than $MAX_QUEUE_LENGTH issue an alert if [ ${Q_ACTIVE} -gt ${MAX_QUEUE_LENGTH} -o ${Q_INCOMING} -gt ${MAX_QUEUE_LENGTH} -o ${Q_DEFERRED} -gt ${MAX_QUEUE_LENGTH} -o ${Q_MAILDROP} -gt ${MAX_QUEUE_LENGTH} ]; then ( echo \"From: ${MAILFROM} \" echo \"To: ${MAILTO} \" echo \"Mime-Version: 1.0\" echo 'Content-Type: text/plain; charset=\"iso-8859-1\"' echo \"Subject: ${MAILSUBJECT}\" echo \"\" echo \"One or more of the postfix queues on ${DOMAIN} has grown beyond ${MAX_QUEUE_LENGTH} messages in length.\" ) | ${MSMTP} --host=${MAILHOST} --port=${MAILPORT} --protocol=${MAILPROTO} --domain=${DOMAIN} --auth=off --tls=off --from=${MAILFROM} --logfile=${LOGFILE} --syslog=off --read-recipients exit 2 fi exit 0","title":"Monitoring"},{"location":"cookbooks/postfix/monitoring/#mailgraph-and-pflogsumm","text":"Want to support HowtoForge? Become a subscriber! Submitted by falko (Contact Author) (Forums) on Mon, 2006-07-03 15:58. :: 4 Fedora Core 5 4.1 Mailgraph There\u2019s no Mailgraph package available for Fedora Core 5, so we must install it manually. First, we need to install the prerequsities that Mailgraph requires: 1 yum install rrdtool rrdtool-perl perl-File-Tail Then we download the Mailgraph sources and copy the Mailgraph scripts to the appropriate locations: 1 cd /tmp\u2028wget http://people.ee.ethz.ch/~dws/software/mailgraph/pub/mailgraph-1.12.tar.gz\u2028tar xvfz mailgraph-1.12.tar.gz\u2028cd mailgraph-1.12\u2028mv mailgraph.pl /usr/local/bin/mailgraph.pl\u2028mv mailgraph-init /etc/init.d/mailgraph Now we must adjust the Mailgraph init script /etc/init.d/mailgraph: 1 vi /etc/init.d/mailgraph On Fedora, the Postfix mail log is /var/log/maillog, so we change 1 2 MAIL_LOG=/var/log/syslog MAIL_LOG=/var/log/maillog Then we add another variable to /etc/init.d/mailgraph, IGNORE_LOCALHOST. If you have integrated a content filter like amavisd into Postfix, add this line 1 IGNORE_LOCALHOST=\"--ignore-localhost\" to the block where the variables like MAIL_LOG are defined. If you don\u2019t use a content filter, add this line instead: 1 IGNORE_LOCALHOST=\"\" In both cases, change 1 2 3 4 nice -19 $MAILGRAPH_PL -l $MAIL_LOG -d \\ --daemon-pid=$PID_FILE --daemon-rrd=$RRD_DIR nice -19 $MAILGRAPH_PL -l $MAIL_LOG -d \\ --daemon-pid=$PID_FILE --daemon-rrd=$RRD_DIR $IGNORE_LOCALHOST So the final script should look like this (in this case, with \u2013ignore-localhost enabled): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #!/bin/sh # $Id: mailgraph-init,v 1.4 2005/06/13 11:23:22 dws Exp $ # example init script for mailgraph # # chkconfig: 2345 82 28 # description: mailgraph postfix log grapher. # # processname: mailgraph.pl # pidfile: /var/run/mailgraph.pid PATH=/bin:/usr/bin MAILGRAPH_PL=/usr/local/bin/mailgraph.pl MAIL_LOG=/var/log/maillog PID_FILE=/var/run/mailgraph.pid RRD_DIR=/var/lib IGNORE_LOCALHOST=\"--ignore-localhost\" case \"$1\" in 'start') echo \"Starting mail statistics grapher: mailgraph\"; nice -19 $MAILGRAPH_PL -l $MAIL_LOG -d \\ --daemon-pid=$PID_FILE --daemon-rrd=$RRD_DIR $IGNORE_LOCALHOST ;; 'stop') echo \"Stopping mail statistics grapher: mailgraph\"; if [ -f $PID_FILE ]; then kill `cat $PID_FILE` rm $PID_FILE else echo \"mailgraph not running\"; fi ;; *) echo \"Usage: $0 { start | stop }\" exit 1 ;; esac exit 0 Next we make the script executable, create the appropriate system startup links and start Mailgraph: 1 chmod 755 /etc/init.d/mailgraph\u2028chkconfig --levels 235 mailgraph on\u2028/etc/init.d/mailgraph start Still in the /tmp/mailgraph-1.12 directory, we move mailgraph.cgi to our cgi-bin directory: 1 mv mailgraph.cgi /var/www/www.example.com/cgi-bin/ Now we open the file and adjust the locations of the two Mailgraph databases. 1 vi /var/www/www.example.com/cgi-bin/mailgraph.cgi Change 1 2 3 4 my $rrd = 'mailgraph.rrd'; # path to where the RRD database is my $rrd_virus = 'mailgraph_virus.rrd'; # path to where the Virus RRD database is my $rrd = '/var/lib/mailgraph.rrd'; # path to where the RRD database is my $rrd_virus = '/var/lib/mailgraph_virus.rrd'; # path to where the Virus RRD database is Then we make the script executable: 1 chmod 755 /var/www/www.example.com/cgi-bin/mailgraph.cgi If you use suExec for the www.example.com web site, you must chown mailgraph.cgi to the appropriate owner and group. Now direct your browser to http://www.example.com/cgi-bin/mailgraph.cgi , and you should see some graphs. Of course, there must be some emails going through your system before you see the first results, so be patient.","title":"Mailgraph And pflogsumm"},{"location":"cookbooks/postfix/monitoring/#42-pflogsumm","text":"The steps differ only slightly from those on Debian and Ubuntu. The main difference is that Postfix logs to /var/log/maillog on Fedora instead of /var/log/mail.log (Debian/Ubuntu) (pay attention to the dot!). First we install pflogsumm: 1 yum install postfix-pflogsumm We want pflogsumm to be run by a cron job each day and send the report to postmaster@example.com . Therefore we must configure our system that it writes one mail log file for 24 hours, and afterwards starts the next mail log so that we can feed the old mail log to pflogsumm. Therefore we configure logrotate (that\u2019s the program that rotates our system\u2019s log files) like this: open /etc/logrotate.conf and append the following stanza to it, after the line # system-specific logs may be configured here: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 vi /etc/logrotate.conf /var/log/maillog { missingok daily rotate 7 create compress start 0 } Also change /etc/logrotate.d/syslog vi /etc/logrotate.d/syslog /var/log/messages /var/log/secure /var/log/maillog /var/log/spooler /var/log/boot.log /var/log/cron { sharedscripts postrotate /bin/kill -HUP `cat /var/run/syslogd.pid 2> /dev/null` 2> /dev/null || true endscript } /var/log/messages /var/log/secure /var/log/spooler /var/log/boot.log /var/log/cron { sharedscripts postrotate /bin/kill -HUP `cat /var/run/syslogd.pid 2> /dev/null` 2> /dev/null || true endscript } There\u2019s a logrotate script in /etc/cron.daily. This script is called everyday between 06:00h and 07:00h. With the configuration we just made, it will copy the current Postfix log /var/log/maillog to /var/log/maillog.0 and compress it, and the compressed file will be /var/log/maillog.0.gz. It will also create a new, empty /var/log/maillog to which Postfix can log for the next 24 hours. Now we create the script /usr/local/sbin/postfix_report.sh which invokes pflogsumm and makes it send the report to postmaster@example.com : 1 2 3 4 5 6 7 8 9 vi /usr/local/sbin/postfix_report.sh #!/bin/sh PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin gunzip /var/log/maillog.0.gz pflogsumm /var/log/maillog.0 | formail -c -I\"Subject: Mail Statistics\" -I\"From: pflogsumm@localhost\" -I\"To: postmaster@example.com\" -I\"Received: from www.example.com ([192.168.0.100])\" | sendmail postmaster@example.com gzip /var/log/maillog.0 exit 0 We must make this script executable: 1 chmod 755 /usr/local/sbin/postfix_report.sh Then we create a cron job which calls the script everyday at 07:00h: crontab -e 0 7 * * * /usr/local/sbin/postfix_report.sh &> /dev/null This will send the report to postmaster@example.com . mailgraph statistics for postfix running on nginx I\u2019m using postfix as my mail server. In order to get nice graphical overview about the server activity I\u2019m using mailgraph.\u2028Mailgraph is a cgi script written in perl. It uses rrdtool to produce daily, weekly, monthly and yearly graphs of received/sent and bounced/rejected mail. Installing mailgraph on debian is as easy as running: 1 aptitude install mailgraph The configuration takes place in /etc/default/mailgraph. Make sure to modify it according to your mail setup. In order to run in on nginx server, one needs to install fcgiwrap and spawn-fcgi first. Nothing simpler than that: 1 aptitude install fcgiwrap spawn-fcgi Configuring nginx to use fcgiwrap requires the following: Creation of the /etc/nginx/conf.d/fcgiwrap.conf file with the following content: 1 2 3 4 5 6 7 8 9 . upstream fcgiwrap { . server unix:/var/run/fcgiwrap.socket; . } . Instructions to the nginx, to pass the cgi scripts to fcgiwrap (done in the server section for the virtual host): . location ~ \\.cgi$ { . root /usr/lib/cgi-bin; . include /etc/nginx/fastcgi_params; . fastcgi_pass fcgiwrap; . } The result for weekly statistics looks like shown below:","title":"4.2 pflogsumm"},{"location":"cookbooks/postfix/monitoring/#simple-bash-monitoring","text":"You can monitor the queues with a simple bashscript: 1 #!/bin/bash # 20.06.2011 - JJaritsch @ ANEXIA Internetdienstleistungs GmbH # jj@anexia.at queuelength=`/usr/sbin/postqueue -p | tail -n1 | awk '{print $5}'` queuecount=`echo $queuelength | grep \"[0-9]\"` if [ \"$queuecount\" == \"\" ]; then echo 0; else echo ${queuelength}; fi exit 35 Save this script and make it executable (0755 is enough) for the snmpd user. The next step is to add the following line to your snmpd.conf: 1 exec postqueue /path/to/your/snmp_monitor_postqueue.sh If you want to use sudo, you can add this line: 1 exec postqueue /usr/bin/sudo /path/to/your/snmp_monitor_postqueue.sh In case of sudo you also have to add the following to your sudoers file (so there is no auth required to execute this script): 1 snmp ALL=(ALL) NOPASSWD: /path/to/your/snmp_monitor_postqueue.sh Reload your snmpd - you will find the count-result in .1.3.6.1.4.1.2021.8.1.101.* (for example in .1.3.6.1.4.1.2021.8.1.101.1 if you have no other additional lines in the snmpd.conf).","title":"Simple Bash Monitoring"},{"location":"cookbooks/postfix/monitoring/#another-monitoring-bash-msmtp","text":"In addition to Bryan Rehbein\u2019s answer above, here\u2019s a script I use to monitor postfix queue lengths. All it does is send an email alert once a queue grows beyond X messages in size. The alert is sent using msmtp (a tiny command line smtp client) so it bypasses the local postfix installation (which you can\u2019t rely on to get your alert out in a timely fashion if its queues are growing\u2026) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #!/bin/bash # # Postfix queue length monitoring script (requires msmtp) # # This script checks the active, incoming, deferred and maildrop postfix queue directories. # # If the number of messages in any of these directories is more than $MAX_QUEUE_LENGTH, # the script will generate an alert email and send it using msmtp. We use msmtp so that # we can bypass the local postfix installation (since if the queues are getting big, # the alert email may not be sent in time to catch the problem). # ######################################################## # # SET SCRIPT VARS ######################################################## # # Path to msmtp binary (e.g. /usr/bin/msmtp on Debian systems) MSMTP=/usr/bin/msmtp # Remote mail host (this is the mail server msmtp will use to send the alert. It should NOT be the local postfix installation) MAILHOST=backup.mailserver.com # Remote mail port MAILPORT=25 # Mail protocol MAILPROTO=smtp # Fully qualified domain name of local postfix installation DOMAIN=primary.mailserver.com # From address MAILFROM=postmaster@mailserver.com # Recipient (this address should not route to the local postfix installation, for obvious reasons) MAILTO=\"alerts@anotherdomain.com\" # Email subject MAILSUBJECT=\"Postfix queue length alert for ${DOMAIN}\" # MSMTP log file LOGFILE=/var/log/msmtp.log # Root of the postfix queue dirs (e.g. /var/spool/postfix on Debian systems). Note: no trailing slash. QUEUEDIR_ROOT=\"/var/spool/postfix\" # Max queue length (if there are more messages in a queue than this number, we will send an alert) MAX_QUEUE_LENGTH=10 ######################################################### # SCRIPT LOGIC STARTS HERE ######################################################### # Check msmtp binary exists if [ ! -f ${MSMTP} ] then echo \"Cannot find ${MSMTP}. Exiting.\" exit 1 fi # Get the number of messages sitting in each postfix queue directory Q_ACTIVE=$(find ${QUEUEDIR_ROOT}/active -type f | wc -l) Q_INCOMING=$(find ${QUEUEDIR_ROOT}/incoming -type f | wc -l) Q_DEFERRED=$(find ${QUEUEDIR_ROOT}/deferred -type f | wc -l) Q_MAILDROP=$(find ${QUEUEDIR_ROOT}/maildrop -type f | wc -l) # If any of these queues contain more than $MAX_QUEUE_LENGTH issue an alert if [ ${Q_ACTIVE} -gt ${MAX_QUEUE_LENGTH} -o ${Q_INCOMING} -gt ${MAX_QUEUE_LENGTH} -o ${Q_DEFERRED} -gt ${MAX_QUEUE_LENGTH} -o ${Q_MAILDROP} -gt ${MAX_QUEUE_LENGTH} ]; then ( echo \"From: ${MAILFROM} \" echo \"To: ${MAILTO} \" echo \"Mime-Version: 1.0\" echo 'Content-Type: text/plain; charset=\"iso-8859-1\"' echo \"Subject: ${MAILSUBJECT}\" echo \"\" echo \"One or more of the postfix queues on ${DOMAIN} has grown beyond ${MAX_QUEUE_LENGTH} messages in length.\" ) | ${MSMTP} --host=${MAILHOST} --port=${MAILPORT} --protocol=${MAILPROTO} --domain=${DOMAIN} --auth=off --tls=off --from=${MAILFROM} --logfile=${LOGFILE} --syslog=off --read-recipients exit 2 fi exit 0","title":"Another monitoring Bash \u2013 MSMTP"},{"location":"cookbooks/postfix/multidomain/","text":"1 mydestination = /etc/postfix/virtual/domains TO BE DONE","title":"Multidomain"},{"location":"cookbooks/postfix/opendmarc/","text":"4.1. Install opendmarc package \u00b6 1 apt-get install opendmarc 4.2. Configuration \u00b6 Copy paste the following into a text file and save as a bash script. You can change the variable \u201cDOMAIN\u201d to the one you choose depending upon the requirement. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 DOMAIN=\"pronostic-facile.fr\" mkdir /usr/local/etc/opendmarc/ cat > /usr/local/etc/opendmarc/ignore.hosts << EOF ${DOMAIN} `hostname` `ifconfig |grep \"inet addr:\"|awk '{print $2}'|cut -d: -f2|uniq` EOF cat > /etc/opendmarc.conf << EOF AuthservID HOSTNAME Background true BaseDirectory /var/run/opendmarc CopyFailuresTo postmaster@${DOMAIN} IgnoreHosts /usr/local/etc/opendmarc/ignore.hosts PidFile /var/run/opendmarc/opendmarc.pid Socket inet:8893@localhost Syslog false SyslogFacility mail TemporaryDirectory /var/tmp TrustedAuthservIDs HOSTNAME UserID opendmarc EOF postconf -e smtpd_milters=\"inet:localhost:8891,inet:localhost:8892,inet:localhost:8893\" postconf -e non_smtpd_milters=\"inet:localhost:8891,inet:localhost:8892,inet:localhost:8893\" service opendmarc restart service postfix restart 4.3. Update DNS \u00b6 Publish the corresponding dns record, 1 _dmarc.pronostic-facile.fr. IN TXT \"v=DMARC1;p=reject;pct=100;rua=mailto:postmaster@pronostic-facile.fr\"","title":"Opendmarc"},{"location":"cookbooks/postfix/opendmarc/#41-install-opendmarc-package","text":"1 apt-get install opendmarc","title":"4.1. Install opendmarc package"},{"location":"cookbooks/postfix/opendmarc/#42-configuration","text":"Copy paste the following into a text file and save as a bash script. You can change the variable \u201cDOMAIN\u201d to the one you choose depending upon the requirement. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 DOMAIN=\"pronostic-facile.fr\" mkdir /usr/local/etc/opendmarc/ cat > /usr/local/etc/opendmarc/ignore.hosts << EOF ${DOMAIN} `hostname` `ifconfig |grep \"inet addr:\"|awk '{print $2}'|cut -d: -f2|uniq` EOF cat > /etc/opendmarc.conf << EOF AuthservID HOSTNAME Background true BaseDirectory /var/run/opendmarc CopyFailuresTo postmaster@${DOMAIN} IgnoreHosts /usr/local/etc/opendmarc/ignore.hosts PidFile /var/run/opendmarc/opendmarc.pid Socket inet:8893@localhost Syslog false SyslogFacility mail TemporaryDirectory /var/tmp TrustedAuthservIDs HOSTNAME UserID opendmarc EOF postconf -e smtpd_milters=\"inet:localhost:8891,inet:localhost:8892,inet:localhost:8893\" postconf -e non_smtpd_milters=\"inet:localhost:8891,inet:localhost:8892,inet:localhost:8893\" service opendmarc restart service postfix restart","title":"4.2. Configuration"},{"location":"cookbooks/postfix/opendmarc/#43-update-dns","text":"Publish the corresponding dns record, 1 _dmarc.pronostic-facile.fr. IN TXT \"v=DMARC1;p=reject;pct=100;rua=mailto:postmaster@pronostic-facile.fr\"","title":"4.3. Update DNS"},{"location":"cookbooks/postfix/rate_limiting/","text":"( http://steam.io/2013/04/01/postfix-rate-limiting/ ) http://wiki.wordtothewise.com/ISP_Summary_Information 6.1. Add policies in /etc/postfix/master.cf \u00b6 1 2 polite unix - - n - - smtp turtle unix - - n - - smtp Map domain to its transport name. For this add the following to /etc/postfix/transport gmail.com polite: yahoo.com turtle: hotmail.com polite: aol.com turtle: Modify postfix configuration to specify the rate limit, postconf -e \u201cpolite_destination_concurrency_limit = 4\u201d postconf -e \u201cpolite_destination_rate_delay = 0\u201d postconf -e \u201cpolite_destination_recipient_limit = 10\u201d postconf -e \u201cturtle_destination_rate_delay = 3s\u201d postconf -e \u201cturtle_destination_concurrency_limit = 20\u201d postconf -e \u201cturtle_destination_recipient_limit = 4\u201d Restart postfix 1 service postfix restart other solution Now, define required additional transport in postfix master.cf file: 1 2 smtp-gmail unix - - n - 1 smtp -o syslog_name=smtp-gmail Define the required throttling (rate limits) settings in postfix main.cf 1 2 3 4 smtp-gmail_destination_rate_delay = 12s smtp-gmail_destination_concurrency_limit = 1 smtp-gmail_destination_recipient_limit = 2 smtp-gmail_initial_destination_concurrency=1 The syntax is as follows: transtport-name_variable-name=value Add the following to /etc/postfix/transport 1 /\\@gmail\\.com$/ smtp-gmail: The format of the above file is regexp. Lookups to regexp tables are fast so probably you should use those. For regexp to work you should have regexp support built into postfix. Find out using this command 1 postconf -m Once the transport file is created, make sure to create the corresponding db, which will be actually used by postfix. Use postmap command. 1 postmap /etc/postfix/transport Make postfix use this transport table. Edit main.cf and add the following: 1 transport_maps = regexp:/etc/postfix/transport Make sure you use regexp prefix. Reload postfix 1 2 3 4 5 6 7 8 postfix reload transport_maps = hash:/etc/postfix/transport, regexp:/etc/postfix/transport_gmail # cat /etc/postfix/transport_gmail /\\@gmail\\.com$/ smtp-gmail: Note No need to postmap this file Delay=2s caused transport invocation every 4 seconds in my experience. /etc/postfix/transport file like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 # Yahoo (USA) yahoo.com yahoo: ymail.com yahoo: rocketmail.com yahoo: # Yahoo (INTL) yahoo.ae yahoo: yahoo.at yahoo: yahoo.be yahoo: yahoo.ca yahoo: yahoo.ch yahoo: yahoo.cn yahoo: yahoo.co.il yahoo: yahoo.co.in yahoo: yahoo.co.jp yahoo: yahoo.co.kr yahoo: yahoo.co.nz yahoo: yahoo.co.th yahoo: yahoo.co.uk yahoo: yahoo.co.za yahoo: yahoo.com.ar yahoo: yahoo.com.au yahoo: yahoo.com.br yahoo: yahoo.com.cn yahoo: yahoo.com.hk yahoo: yahoo.com.mx yahoo: yahoo.com.my yahoo: yahoo.com.ph yahoo: yahoo.com.sg yahoo: yahoo.com.tr yahoo: yahoo.com.tw yahoo: yahoo.com.vn yahoo: yahoo.cz yahoo: yahoo.de yahoo: yahoo.dk yahoo: yahoo.en yahoo: yahoo.es yahoo: yahoo.fi yahoo: yahoo.fr yahoo: yahoo.gr yahoo: yahoo.ie yahoo: yahoo.it yahoo: yahoo.nl yahoo: yahoo.no yahoo: yahoo.pl yahoo: yahoo.pt yahoo: yahoo.ro yahoo: yahoo.ru yahoo: yahoo.se yahoo: # Yahoo ymail.com yahoo: rocketmail.com yahoo: yahoo.com smtpslow: gmail.com smtpslow: hotmail.com smtpslow: aol.com smtpslow: comcast.com smtpslow: live.com smtpslow: msn.com smtpslow: sbcglobal.net smtpslow: verizon.net smtpslow: bellsouth.net smtpslow: yahoo.ca smtpslow: cox.net smtpslow: ymail.com smtpslow: Once you\u2019re done editing the /etc/postfix/transport file (and after every edit from now on), remember to do: # postmap /etc/postfix/transport 1 2 3 4 5 6 7 /etc/postfix/transport.regexp that looks like this: # Yahoo Wildcards /yahoo(\\.[a-z]{2,3}){1,2}$/ yahoo: yahoo unix - - n - - smtp -o syslog_name=postfix-yahoo Back up your /etc/postfix/main.cf file, then add these lines: 1 2 3 4 5 6 transport_maps = hash:/etc/postfix/transport, regexp:/etc/postfix/transport.regexp yahoo_initial_destination_concurrency = 1 yahoo_destination_concurrency_limit = 4 yahoo_destination_recipient_limit = 2 yahoo_destination_rate_delay = 1s This tells Postfix to check your /etc/postfix/transport and /etc/postfix/transport.regexp files to look up which domains you\u2019ve mapped to which transport, then it sets four specific configurations for the \u201cyahoo\u201d transport: yahoo_initial_destination_concurrency = 1 will start out slowly by only sending one message per SMTP connection to a Yahoo\u2019s MTA. yahoo_destination_concurrency_limit = 4 after starting out slowly with just 1 message, Postfix will increase to allow up to four messages per SMTP connection to a Yahoo MTA. yahoo_destination_recipient_limit = 2 will send the same message to no more than 2 recipients at a time yahoo_destination_rate_delay = 1s will add a 1 second delay between the messages final version: 1 2 3 4 5 6 7 8 9 /pronostic-facile\\.fr/ relay:[ASPMX.L.GOOGLE.COM] /gmail\\.com/ polite: /yahoo\\.com/ turtle: /hotmail(\\.[a-z]{2,3}){1,2}$/ polite: /live(\\.[a-z]{2,3}){1,2}$/ polite: /outlook(\\.[a-z]{2,3}){1,2}$/ polite: /aol\\.com/ turtle: /yahoo(\\.[a-z]{2,3}){1,2}$/ turtle: Basically, you may take the following steps as reference: Create a seperate mail for the destination is yahoo, let\u2019s name it \u2018slow\u2019 queue (You may search in this mailling list too, someone has asked before) After Postfix 2.5, set slow_destination_rate_delay for certain period of time for \u2018slow\u2019 In my case, I set to 300s. That\u2019s mean 5 mins per delivery to yahoo Set slow_destination_concurrency_limit & slow_destination_recipient_limit for \u2018slow\u2019 In may case, I set slow_destination_concurrency_limit = 2 slow_destination_recipient_limit = 10 In Postfix 2.5.5 or earlier, disable defer retry failure giving up limit for \u2018slow\u2019. I my case, I set slow_concurrency_failed_cohort_limit = $slow_destination_concurrency_failed_cohort_limit slow_destination_concurrency_failed_cohort_limit = 0 STEP 1: SETTING UP THE TRANSPORT MAPS \u00b6 The first step is to determine which domains you want to treat differently. Obviously, in this example, we\u2019re trying to set up something to eliminate (or at least reduce) Yahoo\u2019s deferrals. So edit the /etc/postfix/transport file and create some maps that tell Postfix exactly which email domains are going to get the special \u201cYahoo\u201d treatment. The email domain goes on the left, and the name of your custom transport goes on the right (always followed by a colon). The most basic approach would be to specifically list all the Yahoo email domains you want to cover in your /etc/postfix/transport file like this: 1 # Yahoo (USA) yahoo.com yahoo: ymail.com yahoo: rocketmail.com yahoo: # Yahoo (INTL) yahoo.ae yahoo: yahoo.at yahoo: yahoo.be yahoo: yahoo.ca yahoo: yahoo.ch yahoo: yahoo.cn yahoo: yahoo.co.il yahoo: yahoo.co.in yahoo: yahoo.co.jp yahoo: yahoo.co.kr yahoo: yahoo.co.nz yahoo: yahoo.co.th yahoo: yahoo.co.uk yahoo: yahoo.co.za yahoo: yahoo.com.ar yahoo: yahoo.com.au yahoo: yahoo.com.br yahoo: yahoo.com.cn yahoo: yahoo.com.hk yahoo: yahoo.com.mx yahoo: yahoo.com.my yahoo: yahoo.com.ph yahoo: yahoo.com.sg yahoo: yahoo.com.tr yahoo: yahoo.com.tw yahoo: yahoo.com.vn yahoo: yahoo.cz yahoo: yahoo.de yahoo: yahoo.dk yahoo: yahoo.en yahoo: yahoo.es yahoo: yahoo.fi yahoo: yahoo.fr yahoo: yahoo.gr yahoo: yahoo.ie yahoo: yahoo.it yahoo: yahoo.nl yahoo: yahoo.no yahoo: yahoo.pl yahoo: yahoo.pt yahoo: yahoo.ro yahoo: yahoo.ru yahoo: yahoo.se yahoo: However, listing all those domains forces you to stay up to date with any new domains that Yahoo might launch. So a smarter approach would be to two transport maps: one that\u2019s a regular hash table, and another with a regular expression that simply catches any domain that starts with yahoo. First, put ymail.com and rocketmail.com in your /etc/postfix/transport file, like this: 1 2 # Yahoo ymail.com yahoo: rocketmail.com yahoo: Once you\u2019re done editing the /etc/postfix/transport file (and after every edit from now on), remember to do: 1 postmap /etc/postfix/transport to build the transport.db file. Next, create a file called /etc/postfix/transport.regexp that looks like this: Yahoo Wildcards /yahoo(.[a-z]{2,3}){1,2}$/ yahoo: \u00b6 That will catch all \u201cyahoo dot anything\u201d domains. Note that you don\u2019t need to run postmap on regular expression tables, so now you\u2019re ready to tell Postfix how to read your transports. Step 2: Include the New Custom Transports in master.cf As always, before messing with /etc/postfix/master.cf, make a backup. Then add the following lines at the bottom: yahoo unix - - n - - smtp -o syslog_name=postfix-yahoo -o smtp_connect_timeout=5 -o smtp_helo_timeout=5 This tells Postfix that the transport called \u201cyahoo\u201d gets handed off to the Postfix smtp process, and the -o syslog_name option tags the use of this transport in the mail log so I easily tell when this transport is used. Step 3: Create Custom Settings in main.cf The third step of the process is to create some custom settings in your main.cf file to tell Postfix exactly what to do differently when it encounters an outbound mail domain that matches your transport maps. Back up your /etc/postfix/main.cf file, then add these lines: transport_maps = hash:/etc/postfix/transport, regexp:/etc/postfix/transport.regexp yahoo_initial_destination_concurrency = 1 yahoo_destination_concurrency_limit = 4 yahoo_destination_recipient_limit = 2 yahoo_destination_rate_delay = 1s This tells Postfix to check your /etc/postfix/transport and/etc/postfix/transport.regexp files to look up which domains you\u2019ve mapped to which transport, then it sets four specific configurations for the \u201cyahoo\u201d transport: \u2022 yahoo_initial_destination_concurrency = 1 will start out slowly by only sending one message per SMTP connection to a Yahoo\u2019s MTA. \u2022 yahoo_destination_concurrency_limit = 4 after starting out slowly with just 1 message, Postfix will increase to allow up to four messages per SMTP connection to a Yahoo MTA. \u2022 yahoo_destination_recipient_limit = 2 will send the same message to no more than 2 recipients at a time \u2022 yahoo_destination_rate_delay = 1s will add a 1 second delay between the messages This is where the Postfix voodoo kicks in for me, so feel free to experiment with these settings and tweak to your liking. The destination concurrency limit and the rate delay are the two you\u2019ll probably want to tinker to keep Yahoo happy. Depending on your mailer reputation, they\u2019ll be more strict or more relaxed on what they\u2019ll allow for these two settings. The above settings that happen to work for my needs, but I still tweak them to experiment, and if you have a configuration that works well with Yahoo (or if you have other custom transports that help increase delivery), please feel free to share them in the comments. Step 4: Restart Postfix and Test Now you\u2019re ready to try things out. Start the Postfix configuration with: service postfix restart \u00b6 You can\u2019t just do a postfix reload, because changes to the master.cf require a full restart. Finally, do a tail -f on your maillog. On my CentOS system, that\u2019s: tail -f /var/log/maillog Now send a message to a Yahoo test account (I\u2019m assuming you have an @yahoo.com test account) from or through your Postfix server. If everything worked right, you should see log entries that start with the date, local hostname, and then say postfix-yahoo/smtp. These are the messages that are being diverted through your new transport! After using these settings for a few mailings, I\u2019ve seen a drastic reduction in the amount of time it takes to deliver tens of thousands of opt-in email to Yahoo recipients. Hopefully, they\u2019ll work for you, too! Your feedback and comments are welcome below, and I\u2019m especially interested to hear of any other custom transports you may be using, as well as your experiences with different settings for Yahoo. \u2003 La file des messages se rempli alors tr\u00e8s rapidement pour monter facilement \u00e0 plusieurs dizaine de milliers de mails en attente d\u2019envoi et surtout totalement bloqu\u00e9s ! Autre souci les mails sont en status deferred, et seront donc supprim\u00e9 de la file dans un d\u00e9lai de 5 jours par d\u00e9faut (voir la configuration demaximal_queue_lifetime). C\u2019est insuffisant pour laisser s\u2019\u00e9couler les mails en attente ! Pour les serveurs de mail que je g\u00e8re j\u2019ai \u00ab bidouill\u00e9 \u00bb un script pour vider manuellement la queue pour les mails destin\u00e9s \u00e0 Orange/Wanadoo afin que les personnes aient leur mail au plus t\u00f4t ! Mais il fallait trouver une solution plus durable\u2026 J\u2019en ai mise une en place, elle n\u2019est pas parfaite mais elle a permis de g\u00e9rer et de d\u00e9livrer les mailings de ces f\u00eates de fin d\u2019ann\u00e9e en temps et en heure ! D\u00e9tails de la solution : transport sp\u00e9cifique pour orange/wanadoo /etc/postfix/transport 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 wanadoo.com slow: wanadoo.fr slow: orange.com slow: orange.fr slow: puis postmap /etc/postfix/transport dans /etc/postfix/master.cf #========================================================================== # service type private unpriv chroot wakeup maxproc command + args # (yes) (yes) (yes) (never) (100) #========================================================================== slow unix - - n - 5 smtp -o syslog_name=postfix-slow -o smtp_destination_concurrency_limit=3 -o slow_destination_rate_delay=1 dans /etc/postfix/main.cf slow_destination_recipient_limit = 20 slow_destination_concurrency_limit = 2 et finalement : /etc/init.d/postfix reload Les mails se stockent tout de m\u00eame en queue, mais la file se vide ensuite relativement rapidement ! orange_destination_recipient_limit = 20 orange_destination_concurrency_limit = 2 orange_destination_concurrency_limit = 3 orange_destination_rate_delay = 1s","title":"Rate limiting"},{"location":"cookbooks/postfix/rate_limiting/#61-add-policies-in-etcpostfixmastercf","text":"1 2 polite unix - - n - - smtp turtle unix - - n - - smtp Map domain to its transport name. For this add the following to /etc/postfix/transport gmail.com polite: yahoo.com turtle: hotmail.com polite: aol.com turtle: Modify postfix configuration to specify the rate limit, postconf -e \u201cpolite_destination_concurrency_limit = 4\u201d postconf -e \u201cpolite_destination_rate_delay = 0\u201d postconf -e \u201cpolite_destination_recipient_limit = 10\u201d postconf -e \u201cturtle_destination_rate_delay = 3s\u201d postconf -e \u201cturtle_destination_concurrency_limit = 20\u201d postconf -e \u201cturtle_destination_recipient_limit = 4\u201d Restart postfix 1 service postfix restart other solution Now, define required additional transport in postfix master.cf file: 1 2 smtp-gmail unix - - n - 1 smtp -o syslog_name=smtp-gmail Define the required throttling (rate limits) settings in postfix main.cf 1 2 3 4 smtp-gmail_destination_rate_delay = 12s smtp-gmail_destination_concurrency_limit = 1 smtp-gmail_destination_recipient_limit = 2 smtp-gmail_initial_destination_concurrency=1 The syntax is as follows: transtport-name_variable-name=value Add the following to /etc/postfix/transport 1 /\\@gmail\\.com$/ smtp-gmail: The format of the above file is regexp. Lookups to regexp tables are fast so probably you should use those. For regexp to work you should have regexp support built into postfix. Find out using this command 1 postconf -m Once the transport file is created, make sure to create the corresponding db, which will be actually used by postfix. Use postmap command. 1 postmap /etc/postfix/transport Make postfix use this transport table. Edit main.cf and add the following: 1 transport_maps = regexp:/etc/postfix/transport Make sure you use regexp prefix. Reload postfix 1 2 3 4 5 6 7 8 postfix reload transport_maps = hash:/etc/postfix/transport, regexp:/etc/postfix/transport_gmail # cat /etc/postfix/transport_gmail /\\@gmail\\.com$/ smtp-gmail: Note No need to postmap this file Delay=2s caused transport invocation every 4 seconds in my experience. /etc/postfix/transport file like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 # Yahoo (USA) yahoo.com yahoo: ymail.com yahoo: rocketmail.com yahoo: # Yahoo (INTL) yahoo.ae yahoo: yahoo.at yahoo: yahoo.be yahoo: yahoo.ca yahoo: yahoo.ch yahoo: yahoo.cn yahoo: yahoo.co.il yahoo: yahoo.co.in yahoo: yahoo.co.jp yahoo: yahoo.co.kr yahoo: yahoo.co.nz yahoo: yahoo.co.th yahoo: yahoo.co.uk yahoo: yahoo.co.za yahoo: yahoo.com.ar yahoo: yahoo.com.au yahoo: yahoo.com.br yahoo: yahoo.com.cn yahoo: yahoo.com.hk yahoo: yahoo.com.mx yahoo: yahoo.com.my yahoo: yahoo.com.ph yahoo: yahoo.com.sg yahoo: yahoo.com.tr yahoo: yahoo.com.tw yahoo: yahoo.com.vn yahoo: yahoo.cz yahoo: yahoo.de yahoo: yahoo.dk yahoo: yahoo.en yahoo: yahoo.es yahoo: yahoo.fi yahoo: yahoo.fr yahoo: yahoo.gr yahoo: yahoo.ie yahoo: yahoo.it yahoo: yahoo.nl yahoo: yahoo.no yahoo: yahoo.pl yahoo: yahoo.pt yahoo: yahoo.ro yahoo: yahoo.ru yahoo: yahoo.se yahoo: # Yahoo ymail.com yahoo: rocketmail.com yahoo: yahoo.com smtpslow: gmail.com smtpslow: hotmail.com smtpslow: aol.com smtpslow: comcast.com smtpslow: live.com smtpslow: msn.com smtpslow: sbcglobal.net smtpslow: verizon.net smtpslow: bellsouth.net smtpslow: yahoo.ca smtpslow: cox.net smtpslow: ymail.com smtpslow: Once you\u2019re done editing the /etc/postfix/transport file (and after every edit from now on), remember to do: # postmap /etc/postfix/transport 1 2 3 4 5 6 7 /etc/postfix/transport.regexp that looks like this: # Yahoo Wildcards /yahoo(\\.[a-z]{2,3}){1,2}$/ yahoo: yahoo unix - - n - - smtp -o syslog_name=postfix-yahoo Back up your /etc/postfix/main.cf file, then add these lines: 1 2 3 4 5 6 transport_maps = hash:/etc/postfix/transport, regexp:/etc/postfix/transport.regexp yahoo_initial_destination_concurrency = 1 yahoo_destination_concurrency_limit = 4 yahoo_destination_recipient_limit = 2 yahoo_destination_rate_delay = 1s This tells Postfix to check your /etc/postfix/transport and /etc/postfix/transport.regexp files to look up which domains you\u2019ve mapped to which transport, then it sets four specific configurations for the \u201cyahoo\u201d transport: yahoo_initial_destination_concurrency = 1 will start out slowly by only sending one message per SMTP connection to a Yahoo\u2019s MTA. yahoo_destination_concurrency_limit = 4 after starting out slowly with just 1 message, Postfix will increase to allow up to four messages per SMTP connection to a Yahoo MTA. yahoo_destination_recipient_limit = 2 will send the same message to no more than 2 recipients at a time yahoo_destination_rate_delay = 1s will add a 1 second delay between the messages final version: 1 2 3 4 5 6 7 8 9 /pronostic-facile\\.fr/ relay:[ASPMX.L.GOOGLE.COM] /gmail\\.com/ polite: /yahoo\\.com/ turtle: /hotmail(\\.[a-z]{2,3}){1,2}$/ polite: /live(\\.[a-z]{2,3}){1,2}$/ polite: /outlook(\\.[a-z]{2,3}){1,2}$/ polite: /aol\\.com/ turtle: /yahoo(\\.[a-z]{2,3}){1,2}$/ turtle: Basically, you may take the following steps as reference: Create a seperate mail for the destination is yahoo, let\u2019s name it \u2018slow\u2019 queue (You may search in this mailling list too, someone has asked before) After Postfix 2.5, set slow_destination_rate_delay for certain period of time for \u2018slow\u2019 In my case, I set to 300s. That\u2019s mean 5 mins per delivery to yahoo Set slow_destination_concurrency_limit & slow_destination_recipient_limit for \u2018slow\u2019 In may case, I set slow_destination_concurrency_limit = 2 slow_destination_recipient_limit = 10 In Postfix 2.5.5 or earlier, disable defer retry failure giving up limit for \u2018slow\u2019. I my case, I set slow_concurrency_failed_cohort_limit = $slow_destination_concurrency_failed_cohort_limit slow_destination_concurrency_failed_cohort_limit = 0","title":"6.1. Add policies in /etc/postfix/master.cf"},{"location":"cookbooks/postfix/rate_limiting/#step-1-setting-up-the-transport-maps","text":"The first step is to determine which domains you want to treat differently. Obviously, in this example, we\u2019re trying to set up something to eliminate (or at least reduce) Yahoo\u2019s deferrals. So edit the /etc/postfix/transport file and create some maps that tell Postfix exactly which email domains are going to get the special \u201cYahoo\u201d treatment. The email domain goes on the left, and the name of your custom transport goes on the right (always followed by a colon). The most basic approach would be to specifically list all the Yahoo email domains you want to cover in your /etc/postfix/transport file like this: 1 # Yahoo (USA) yahoo.com yahoo: ymail.com yahoo: rocketmail.com yahoo: # Yahoo (INTL) yahoo.ae yahoo: yahoo.at yahoo: yahoo.be yahoo: yahoo.ca yahoo: yahoo.ch yahoo: yahoo.cn yahoo: yahoo.co.il yahoo: yahoo.co.in yahoo: yahoo.co.jp yahoo: yahoo.co.kr yahoo: yahoo.co.nz yahoo: yahoo.co.th yahoo: yahoo.co.uk yahoo: yahoo.co.za yahoo: yahoo.com.ar yahoo: yahoo.com.au yahoo: yahoo.com.br yahoo: yahoo.com.cn yahoo: yahoo.com.hk yahoo: yahoo.com.mx yahoo: yahoo.com.my yahoo: yahoo.com.ph yahoo: yahoo.com.sg yahoo: yahoo.com.tr yahoo: yahoo.com.tw yahoo: yahoo.com.vn yahoo: yahoo.cz yahoo: yahoo.de yahoo: yahoo.dk yahoo: yahoo.en yahoo: yahoo.es yahoo: yahoo.fi yahoo: yahoo.fr yahoo: yahoo.gr yahoo: yahoo.ie yahoo: yahoo.it yahoo: yahoo.nl yahoo: yahoo.no yahoo: yahoo.pl yahoo: yahoo.pt yahoo: yahoo.ro yahoo: yahoo.ru yahoo: yahoo.se yahoo: However, listing all those domains forces you to stay up to date with any new domains that Yahoo might launch. So a smarter approach would be to two transport maps: one that\u2019s a regular hash table, and another with a regular expression that simply catches any domain that starts with yahoo. First, put ymail.com and rocketmail.com in your /etc/postfix/transport file, like this: 1 2 # Yahoo ymail.com yahoo: rocketmail.com yahoo: Once you\u2019re done editing the /etc/postfix/transport file (and after every edit from now on), remember to do: 1 postmap /etc/postfix/transport to build the transport.db file. Next, create a file called /etc/postfix/transport.regexp that looks like this:","title":"STEP 1: SETTING UP THE TRANSPORT MAPS"},{"location":"cookbooks/postfix/rate_limiting/#yahoo-wildcards-yahooa-z2312-yahoo","text":"That will catch all \u201cyahoo dot anything\u201d domains. Note that you don\u2019t need to run postmap on regular expression tables, so now you\u2019re ready to tell Postfix how to read your transports. Step 2: Include the New Custom Transports in master.cf As always, before messing with /etc/postfix/master.cf, make a backup. Then add the following lines at the bottom: yahoo unix - - n - - smtp -o syslog_name=postfix-yahoo -o smtp_connect_timeout=5 -o smtp_helo_timeout=5 This tells Postfix that the transport called \u201cyahoo\u201d gets handed off to the Postfix smtp process, and the -o syslog_name option tags the use of this transport in the mail log so I easily tell when this transport is used. Step 3: Create Custom Settings in main.cf The third step of the process is to create some custom settings in your main.cf file to tell Postfix exactly what to do differently when it encounters an outbound mail domain that matches your transport maps. Back up your /etc/postfix/main.cf file, then add these lines: transport_maps = hash:/etc/postfix/transport, regexp:/etc/postfix/transport.regexp yahoo_initial_destination_concurrency = 1 yahoo_destination_concurrency_limit = 4 yahoo_destination_recipient_limit = 2 yahoo_destination_rate_delay = 1s This tells Postfix to check your /etc/postfix/transport and/etc/postfix/transport.regexp files to look up which domains you\u2019ve mapped to which transport, then it sets four specific configurations for the \u201cyahoo\u201d transport: \u2022 yahoo_initial_destination_concurrency = 1 will start out slowly by only sending one message per SMTP connection to a Yahoo\u2019s MTA. \u2022 yahoo_destination_concurrency_limit = 4 after starting out slowly with just 1 message, Postfix will increase to allow up to four messages per SMTP connection to a Yahoo MTA. \u2022 yahoo_destination_recipient_limit = 2 will send the same message to no more than 2 recipients at a time \u2022 yahoo_destination_rate_delay = 1s will add a 1 second delay between the messages This is where the Postfix voodoo kicks in for me, so feel free to experiment with these settings and tweak to your liking. The destination concurrency limit and the rate delay are the two you\u2019ll probably want to tinker to keep Yahoo happy. Depending on your mailer reputation, they\u2019ll be more strict or more relaxed on what they\u2019ll allow for these two settings. The above settings that happen to work for my needs, but I still tweak them to experiment, and if you have a configuration that works well with Yahoo (or if you have other custom transports that help increase delivery), please feel free to share them in the comments. Step 4: Restart Postfix and Test Now you\u2019re ready to try things out. Start the Postfix configuration with:","title":"Yahoo Wildcards /yahoo(.[a-z]{2,3}){1,2}$/  yahoo:"},{"location":"cookbooks/postfix/rate_limiting/#service-postfix-restart","text":"You can\u2019t just do a postfix reload, because changes to the master.cf require a full restart. Finally, do a tail -f on your maillog. On my CentOS system, that\u2019s: tail -f /var/log/maillog Now send a message to a Yahoo test account (I\u2019m assuming you have an @yahoo.com test account) from or through your Postfix server. If everything worked right, you should see log entries that start with the date, local hostname, and then say postfix-yahoo/smtp. These are the messages that are being diverted through your new transport! After using these settings for a few mailings, I\u2019ve seen a drastic reduction in the amount of time it takes to deliver tens of thousands of opt-in email to Yahoo recipients. Hopefully, they\u2019ll work for you, too! Your feedback and comments are welcome below, and I\u2019m especially interested to hear of any other custom transports you may be using, as well as your experiences with different settings for Yahoo. \u2003 La file des messages se rempli alors tr\u00e8s rapidement pour monter facilement \u00e0 plusieurs dizaine de milliers de mails en attente d\u2019envoi et surtout totalement bloqu\u00e9s ! Autre souci les mails sont en status deferred, et seront donc supprim\u00e9 de la file dans un d\u00e9lai de 5 jours par d\u00e9faut (voir la configuration demaximal_queue_lifetime). C\u2019est insuffisant pour laisser s\u2019\u00e9couler les mails en attente ! Pour les serveurs de mail que je g\u00e8re j\u2019ai \u00ab bidouill\u00e9 \u00bb un script pour vider manuellement la queue pour les mails destin\u00e9s \u00e0 Orange/Wanadoo afin que les personnes aient leur mail au plus t\u00f4t ! Mais il fallait trouver une solution plus durable\u2026 J\u2019en ai mise une en place, elle n\u2019est pas parfaite mais elle a permis de g\u00e9rer et de d\u00e9livrer les mailings de ces f\u00eates de fin d\u2019ann\u00e9e en temps et en heure ! D\u00e9tails de la solution : transport sp\u00e9cifique pour orange/wanadoo /etc/postfix/transport 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 wanadoo.com slow: wanadoo.fr slow: orange.com slow: orange.fr slow: puis postmap /etc/postfix/transport dans /etc/postfix/master.cf #========================================================================== # service type private unpriv chroot wakeup maxproc command + args # (yes) (yes) (yes) (never) (100) #========================================================================== slow unix - - n - 5 smtp -o syslog_name=postfix-slow -o smtp_destination_concurrency_limit=3 -o slow_destination_rate_delay=1 dans /etc/postfix/main.cf slow_destination_recipient_limit = 20 slow_destination_concurrency_limit = 2 et finalement : /etc/init.d/postfix reload Les mails se stockent tout de m\u00eame en queue, mais la file se vide ensuite relativement rapidement ! orange_destination_recipient_limit = 20 orange_destination_concurrency_limit = 2 orange_destination_concurrency_limit = 3 orange_destination_rate_delay = 1s","title":"service postfix restart"},{"location":"cookbooks/postfix/whitelisting/","text":"Whitelisting Important steps FBL (FeedBack Loops) Warming Up Whitelisting AOL WHITELISTENING \u00b6 URL : http://postmaster.aol.com/cgi-bin/wh...list_guides.pl It\u2019s very easy to get on their whitelist, but if they get tons of spam complains about your message, you will be removed to blacklist list very fast ^^ YAHOO WHITELISTENING \u00b6 URL : http://help.yahoo.com/l/us/yahoo/mai...er/bulkv2.html http://help.yahoo.com/l/qe/snova/mail/postmaster/defer.html https://help.yahoo.com/kb/postmaster/complaint-feedback-loop-sln3438.html It\u2019s hard to get whitelisted on Yahoo, but give it a try. HOTMAIL WHITELISTENING \u00b6 URL : https://support.msn.com/eform.aspx?p...rpp&ct=eformts https://mail.live.com/mail/postmaster.aspx https://postmaster.live.com/snds/ SPAM FILTERS WHERE YOU CAN ASK FOR WHITELISTENING \u00b6 http://ipremoval.sms.symantec.com/lookup/ - http://v4bl.org/ http://www.spamhauswhitelist.com/en/ - only with invite, so it\u2019s almost impossible to get there, but it\u2019s worth if you can Checking: http://multirbl.valli.org/ https://www.evernote.com/shard/s11/nl/1281903/fc45a5aa-7acd-4695-98df-92597e7180e2/","title":"Whitelisting"},{"location":"cookbooks/postfix/whitelisting/#aol-whitelistening","text":"URL : http://postmaster.aol.com/cgi-bin/wh...list_guides.pl It\u2019s very easy to get on their whitelist, but if they get tons of spam complains about your message, you will be removed to blacklist list very fast ^^","title":"AOL WHITELISTENING"},{"location":"cookbooks/postfix/whitelisting/#yahoo-whitelistening","text":"URL : http://help.yahoo.com/l/us/yahoo/mai...er/bulkv2.html http://help.yahoo.com/l/qe/snova/mail/postmaster/defer.html https://help.yahoo.com/kb/postmaster/complaint-feedback-loop-sln3438.html It\u2019s hard to get whitelisted on Yahoo, but give it a try.","title":"YAHOO WHITELISTENING"},{"location":"cookbooks/postfix/whitelisting/#hotmail-whitelistening","text":"URL : https://support.msn.com/eform.aspx?p...rpp&ct=eformts https://mail.live.com/mail/postmaster.aspx https://postmaster.live.com/snds/","title":"HOTMAIL WHITELISTENING"},{"location":"cookbooks/postfix/whitelisting/#spam-filters-where-you-can-ask-for-whitelistening","text":"http://ipremoval.sms.symantec.com/lookup/ - http://v4bl.org/ http://www.spamhauswhitelist.com/en/ - only with invite, so it\u2019s almost impossible to get there, but it\u2019s worth if you can Checking: http://multirbl.valli.org/ https://www.evernote.com/shard/s11/nl/1281903/fc45a5aa-7acd-4695-98df-92597e7180e2/","title":"SPAM FILTERS WHERE YOU CAN ASK FOR WHITELISTENING"},{"location":"cookbooks/vuejs3/","text":"Concepts \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 < template > < div > < button > Counter < /button>> < /div> < /template> < script > import { onMounted , computed , ref , watch } from 'vue' export default { props : { status : { type : string , default : '' } }, data() { }, setup ( props , context ) { onMounted (() => { }) const counter = ref ( 0 ) // make counter reactive using a proxy const increment = () => counter . value ++ watch ( counter , current => {}) const arrayOfItems = computer (() => { }) return { counter , increment } // accessible in template } } < /script> Lifecycle Hooks \u00b6 Composition API \u00b6 setup 1. Props 2. Setup 3. Component created onMounted watch computed Reactivity \u00b6 Js Proxy (ES6) reactive 1 const obj = reactive ({...}) ref reactive for a simple type toRefs deconstruct customRef can be used to check / validate values Teleport \u00b6 Outside the compnents tree component Vue dependency injection \u00b6 provide / inject 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 < script > // propertyProvider import { provide } from 'vue' export default { setup () { const property = reactive ({ ... }) provide ( 'key' , property ) watch ( property , property => { }) } } </ script > < script > // action import { inject } from 'vue' setup () { const property = inject ( 'property' , defaultValue ? ) return { property } } </ script > < script > // action import { inject } from 'vue' setup () { const property = inject ( 'property' , defaultValue ? ) return { property } } </ script > context Vuex 4 \u00b6 Can be replaced by reactive(const state = {}) for simple use cases 1 2 3 4 5 6 7 8 import { createStore } from \"vuex\" ; export default createStore ({ state : {}, mutations : {}, actions : {}, modules : {} }); 1 2 3 4 5 6 import router from \"./router\" ; createApp ( App ) . use ( store ) . use ( router ) . mount ( \"#app\" ); Router \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import { createRouter , createWebHistory , RouteRecordRaw } from \"vue-router\" ; import Home from \"../views/Home.vue\" ; const routes : Array < RouteRecordRaw > = [ { path : \"/\" , name : \"Home\" , component : Home }, { path : \"/about\" , name : \"About\" , // route level code-splitting // this generates a separate chunk (about.[hash].js) for this route // which is lazy-loaded when the route is visited. component : () => import ( /* webpackChunkName: \"about\" */ \"../views/About.vue\" ) } ]; const router = createRouter ({ history : createWebHistory ( process . env . BASE_URL ), routes }); export default router ; Typescript \u00b6 shims-vue-d-ts import component by default Vitejs \u00b6","title":"From Vuejs 2.0"},{"location":"cookbooks/vuejs3/#concepts","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 < template > < div > < button > Counter < /button>> < /div> < /template> < script > import { onMounted , computed , ref , watch } from 'vue' export default { props : { status : { type : string , default : '' } }, data() { }, setup ( props , context ) { onMounted (() => { }) const counter = ref ( 0 ) // make counter reactive using a proxy const increment = () => counter . value ++ watch ( counter , current => {}) const arrayOfItems = computer (() => { }) return { counter , increment } // accessible in template } } < /script>","title":"Concepts"},{"location":"cookbooks/vuejs3/#lifecycle-hooks","text":"","title":"Lifecycle Hooks"},{"location":"cookbooks/vuejs3/#composition-api","text":"setup 1. Props 2. Setup 3. Component created onMounted watch computed","title":"Composition API"},{"location":"cookbooks/vuejs3/#reactivity","text":"Js Proxy (ES6) reactive 1 const obj = reactive ({...}) ref reactive for a simple type toRefs deconstruct customRef can be used to check / validate values","title":"Reactivity"},{"location":"cookbooks/vuejs3/#teleport","text":"Outside the compnents tree component","title":"Teleport"},{"location":"cookbooks/vuejs3/#vue-dependency-injection","text":"provide / inject 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 < script > // propertyProvider import { provide } from 'vue' export default { setup () { const property = reactive ({ ... }) provide ( 'key' , property ) watch ( property , property => { }) } } </ script > < script > // action import { inject } from 'vue' setup () { const property = inject ( 'property' , defaultValue ? ) return { property } } </ script > < script > // action import { inject } from 'vue' setup () { const property = inject ( 'property' , defaultValue ? ) return { property } } </ script > context","title":"Vue dependency injection"},{"location":"cookbooks/vuejs3/#vuex-4","text":"Can be replaced by reactive(const state = {}) for simple use cases 1 2 3 4 5 6 7 8 import { createStore } from \"vuex\" ; export default createStore ({ state : {}, mutations : {}, actions : {}, modules : {} }); 1 2 3 4 5 6 import router from \"./router\" ; createApp ( App ) . use ( store ) . use ( router ) . mount ( \"#app\" );","title":"Vuex 4"},{"location":"cookbooks/vuejs3/#router","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import { createRouter , createWebHistory , RouteRecordRaw } from \"vue-router\" ; import Home from \"../views/Home.vue\" ; const routes : Array < RouteRecordRaw > = [ { path : \"/\" , name : \"Home\" , component : Home }, { path : \"/about\" , name : \"About\" , // route level code-splitting // this generates a separate chunk (about.[hash].js) for this route // which is lazy-loaded when the route is visited. component : () => import ( /* webpackChunkName: \"about\" */ \"../views/About.vue\" ) } ]; const router = createRouter ({ history : createWebHistory ( process . env . BASE_URL ), routes }); export default router ;","title":"Router"},{"location":"cookbooks/vuejs3/#typescript","text":"shims-vue-d-ts import component by default","title":"Typescript"},{"location":"cookbooks/vuejs3/#vitejs","text":"","title":"Vitejs"},{"location":"links/online-dev/","text":"","title":"Online dev"},{"location":"projects/Tailwind%20Semantic%20UI/","text":"Colors \u00b6 primary main brand color light accent bring attention dark accent bring attention light shades background dark shades text on light backgound Grid \u00b6 Typography \u00b6 Base components \u00b6 Titles \u00b6 h1 , h2 , h3 , h4 Lists \u00b6 ul table \u00b6 Forms \u00b6 btn input","title":"Tailwind Semantic UI"},{"location":"projects/Tailwind%20Semantic%20UI/#colors","text":"primary main brand color light accent bring attention dark accent bring attention light shades background dark shades text on light backgound","title":"Colors"},{"location":"projects/Tailwind%20Semantic%20UI/#grid","text":"","title":"Grid"},{"location":"projects/Tailwind%20Semantic%20UI/#typography","text":"","title":"Typography"},{"location":"projects/Tailwind%20Semantic%20UI/#base-components","text":"","title":"Base components"},{"location":"projects/Tailwind%20Semantic%20UI/#titles","text":"h1 , h2 , h3 , h4","title":"Titles"},{"location":"projects/Tailwind%20Semantic%20UI/#lists","text":"ul","title":"Lists"},{"location":"projects/Tailwind%20Semantic%20UI/#table","text":"","title":"table"},{"location":"projects/Tailwind%20Semantic%20UI/#forms","text":"btn input","title":"Forms"},{"location":"projects/cloud_mta/","text":"","title":"Index"},{"location":"projects/cloud_pipeline/","text":"On the way to find a way to execute batch video and control the flow, I looked at the different solutions. Goal: - preferrably using containers - lightweight: low overhead - easy to setup and maintain: the main goal of the project is to generate videos, this is limited and simple scope, the workflow should help to facilitate the management not make it more complicated Solutions retained: Airflow Luigi Argo Dask Ideal solution \u00b6 Docker Swarm is easy to setup, Kubernetes much more complex, the goal is to find a way to execute jobs in a ligthweight environemnet, being able to track what is going on, trace of flow. Ideally a graphic intergfce, an easy way to define flow (yaml over python)","title":"Cloud Pipeline"},{"location":"projects/cloud_pipeline/#ideal-solution","text":"Docker Swarm is easy to setup, Kubernetes much more complex, the goal is to find a way to execute jobs in a ligthweight environemnet, being able to track what is going on, trace of flow. Ideally a graphic intergfce, an easy way to define flow (yaml over python)","title":"Ideal solution"},{"location":"projects/cloud_pipeline/airflow_docker/","text":"Airflow \u00b6 Airflow Docker Operator \u00b6 Note Pensez \u00e0 verni 1 2 def method (): print \"hello\"","title":"Airflow and Docker"},{"location":"projects/cloud_pipeline/airflow_docker/#airflow","text":"","title":"Airflow"},{"location":"projects/cloud_pipeline/airflow_docker/#airflow-docker-operator","text":"Note Pensez \u00e0 verni 1 2 def method (): print \"hello\"","title":"Airflow Docker Operator"},{"location":"projects/cloud_pipeline/luigi_docker/","text":"","title":"Luigi docker"},{"location":"projects/cloud_pipeline/prefect/","text":"Prefect \u00b6 Prefect with Docker Swarm","title":"Prefect"},{"location":"projects/cloud_pipeline/prefect/#prefect","text":"Prefect with Docker Swarm","title":"Prefect"},{"location":"projects/cloud_pipeline/vocabulary/","text":"Airflow vocabulary \u00b6 Task or Operator: A defined unit of work. Task instance: An individual run of a single task. The states could be running, success, failed, skipped, and up for retry. DAG (Directed Acyclic Graph): A set of tasks with an execution order. DAG Run: Individual DAG run. Web Server: It is the UI of airflow, it also allows us to manage users, roles, and different configurations for the Airflow setup. Scheduler: Schedules the jobs or orchestrates the tasks. It uses the DAGs object to decide what tasks need to be run, when, and where. Executor: Executes the tasks. There are different types of executors: Sequential: Runs one task instance at a time. Local: Runs tasks by spawning processes in a controlled fashion in different modes. Celery: An asynchronous task queue/job queue based on distributed message passing. For CeleryExecutor, one needs to set up a queue (Redis, RabbitMQ or any other task broker supported by Celery) on which all the celery workers running keep on polling for any new tasks to run Kubernetes: Provides a way to run Airflow tasks on Kubernetes, Kubernetes launch a new pod for each task. Metadata Database: Stores the Airflow states. Airflow uses SqlAlchemy and Object Relational Mapping (ORM) written in Python to connect to the metadata database.","title":"Vocabulary"},{"location":"projects/cloud_pipeline/vocabulary/#airflow-vocabulary","text":"Task or Operator: A defined unit of work. Task instance: An individual run of a single task. The states could be running, success, failed, skipped, and up for retry. DAG (Directed Acyclic Graph): A set of tasks with an execution order. DAG Run: Individual DAG run. Web Server: It is the UI of airflow, it also allows us to manage users, roles, and different configurations for the Airflow setup. Scheduler: Schedules the jobs or orchestrates the tasks. It uses the DAGs object to decide what tasks need to be run, when, and where. Executor: Executes the tasks. There are different types of executors: Sequential: Runs one task instance at a time. Local: Runs tasks by spawning processes in a controlled fashion in different modes. Celery: An asynchronous task queue/job queue based on distributed message passing. For CeleryExecutor, one needs to set up a queue (Redis, RabbitMQ or any other task broker supported by Celery) on which all the celery workers running keep on polling for any new tasks to run Kubernetes: Provides a way to run Airflow tasks on Kubernetes, Kubernetes launch a new pod for each task. Metadata Database: Stores the Airflow states. Airflow uses SqlAlchemy and Object Relational Mapping (ORM) written in Python to connect to the metadata database.","title":"Airflow vocabulary"},{"location":"projects/repositories/all/","text":"Repositories \u00b6 Bear Power Pack https://github.com/sbusso/Bear-Power-Pack HMTL render service https://github.com/sbusso/html-render Flask Google Cloud Run https://github.com/sbusso/flask-gcrun vue-tailwind-template https://github.com/sbusso/vue-tailwind-template Autobackup https://github.com/sbusso/autobackup Workflow Simple library for embedded workflow mechanism. Support serial and parallel exectution. Code abstracted and then extracted from a complex application. I havent checked other available libraries as this one was built from a growing application. https://github.com/sbusso/workflow","title":"Repositories"},{"location":"projects/repositories/all/#repositories","text":"Bear Power Pack https://github.com/sbusso/Bear-Power-Pack HMTL render service https://github.com/sbusso/html-render Flask Google Cloud Run https://github.com/sbusso/flask-gcrun vue-tailwind-template https://github.com/sbusso/vue-tailwind-template Autobackup https://github.com/sbusso/autobackup Workflow Simple library for embedded workflow mechanism. Support serial and parallel exectution. Code abstracted and then extracted from a complex application. I havent checked other available libraries as this one was built from a growing application. https://github.com/sbusso/workflow","title":"Repositories"},{"location":"projects/repositories/alpine-curl/","text":"Used to test content of website via curl 1 2 docker run --rm -e SITE='https://example.com' -e \\ CONTENT=test sbusso/alpine-curl; echo $? github: https://github.com/sbusso/alpine-curl docker: https://hub.docker.com/repository/docker/sbusso/alpine-curl","title":"Alpine curl"},{"location":"projects/repositories/bear-power-pack/","text":"Bear Power Pack \u00b6 https://github.com/sbusso/Bear-Power-Pack","title":"Bear Power Pack"},{"location":"projects/repositories/bear-power-pack/#bear-power-pack","text":"https://github.com/sbusso/Bear-Power-Pack","title":"Bear Power Pack"}]}